{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca2210f-c1bd-4bf3-b531-72887a753a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e151e1e-39eb-487c-9f6f-cbff2bbc0310",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding, get_scheduler\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "792c3ded-c7fa-4d3c-a0dc-9324be326ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adept_data_path = \"../datasets/adept/train-dev-test-split\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "206a738e-9e95-40b5-bcd9-945e82632654",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datasets/adept/train-dev-test-split'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adept_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2b29ab3-c314-4d0e-9321-0dca5c0b220c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = \"train.json\"\n",
    "validation_split = \"val.json\"\n",
    "test_split = \"test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dca2f66-9c00-4957-b2ea-56942f6c2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    \"train\": \"{}/{}\".format(adept_data_path, train_split), \n",
    "    \"validation\": \"{}/{}\".format(adept_data_path, validation_split), \n",
    "    \"test\": \"{}/{}\".format(adept_data_path, test_split),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86f7e1e9-e83f-4ffd-b60a-7bfd0daba9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence2', 'label', 'idx', 'sentence1', 'modifier', 'noun'],\n",
       "        num_rows: 12892\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence2', 'label', 'idx', 'sentence1', 'modifier', 'noun'],\n",
       "        num_rows: 1611\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence2', 'label', 'idx', 'sentence1', 'modifier', 'noun'],\n",
       "        num_rows: 1612\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adept_dataset = load_dataset(\"json\", data_files=data_files)\n",
    "adept_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a404297-d150-4cec-a27d-a89d30f0c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\n",
    "    \"BERT\": \"bert-base-uncased\",\n",
    "    \"ROBERTA\": \"grammarly/detexd-roberta-base\",\n",
    "    \"DEBERTA\": \"sileod/deberta-v3-base-tasksource-nli\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da8496db-474f-42ff-bdca-e952b355f08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = {\n",
    "    \"learning_rate\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a2e8d774-1207-4339-8d23-6503f5ee96aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_dataset = tokenized_dataset.remove_columns(['sentence1', 'sentence2', 'idx'])\n",
    "# tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "# tokenized_dataset = tokenized_dataset.with_format(\"torch\")\n",
    "# tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da7cdcbd-2b3e-4130-a73e-45c329c66d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f284ae87-4db7-4312-9954-41725efc6e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc =  evaluate.load(\"roc_auc\", \"multiclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f2c0873-8961-4196-9887-15ee1339fe5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    logits_tensor = torch.from_numpy(logits)\n",
    "    probabilities = torch.nn.functional.softmax(logits_tensor, dim=-1)\n",
    "    # preds = np.argmax(logits, axis=-1)\n",
    "    return roc_auc.compute(prediction_scores=probabilities, references=labels, multi_class='ovo', average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69184e1e-964b-4943-8292-59029d28abd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b302f6d0-95e5-4580-b094-280fdcab6b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from transformers import Trainer, TrainingArguments, AutoModelForSequenceClassification, DataCollatorWithPadding\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5f579719-a848-407e-8ba6-9312a963b27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'learning_rate': 3.660515504756857e-05,\n",
    " 'num_train_epochs': 3,\n",
    " 'model_name': 'microsoft/deberta-base'}\n",
    "best_model_name = best_params[\"model_name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5400ed94-3268-4210-b4be-e762c312eb6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4836' max='4836' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4836/4836 14:01, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Roc Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.877600</td>\n",
       "      <td>0.888738</td>\n",
       "      <td>0.699447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.780600</td>\n",
       "      <td>0.888433</td>\n",
       "      <td>0.727887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.585800</td>\n",
       "      <td>1.040725</td>\n",
       "      <td>0.710056</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4836, training_loss=0.7740176495093762, metrics={'train_runtime': 842.6723, 'train_samples_per_second': 45.897, 'train_steps_per_second': 5.739, 'total_flos': 324596153516232.0, 'train_loss': 0.7740176495093762, 'epoch': 3.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Fine-tune the best model with the best hyperparameters\n",
    "final_model = AutoModelForSequenceClassification.from_pretrained(best_model_name, num_labels=5, ignore_mismatched_sizes=True)\n",
    "final_tokenizer = AutoTokenizer.from_pretrained(best_model_name)\n",
    "final_data_collator = DataCollatorWithPadding(tokenizer=final_tokenizer)\n",
    "final_tokenized_dataset = adept_dataset.map(lambda x:final_tokenizer(x['sentence2'], truncation=True))\n",
    "final_tokenized_dataset = final_tokenized_dataset.remove_columns(['sentence1', 'sentence2', 'idx', 'modifier', 'noun'])\n",
    "final_tokenized_dataset = final_tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "final_tokenized_dataset = final_tokenized_dataset.with_format(\"torch\")\n",
    "\n",
    "final_trainer = Trainer(\n",
    "    model=final_model,\n",
    "    args=TrainingArguments(\n",
    "        output_dir=f\"./final_output_{best_model_name}\",\n",
    "        learning_rate=best_params[\"learning_rate\"],\n",
    "        num_train_epochs=best_params[\"num_train_epochs\"],\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        # add other training arguments\n",
    "    ),\n",
    "    data_collator=final_data_collator,\n",
    "    train_dataset=final_tokenized_dataset[\"train\"],\n",
    "    eval_dataset=final_tokenized_dataset[\"validation\"],\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "final_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92f0011e-b953-4649-84d7-abe78070dfe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='202' max='202' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [202/202 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_results = final_trainer.evaluate(final_tokenized_dataset['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b30b2569-4ff5-46aa-b020-b38cb0384327",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.939876914024353,\n",
       " 'eval_roc_auc': 0.7260289074261056,\n",
       " 'eval_runtime': 5.2499,\n",
       " 'eval_samples_per_second': 307.055,\n",
       " 'eval_steps_per_second': 38.477,\n",
       " 'epoch': 3.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c40850a-2429-4bdb-a79f-41b9e041b779",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
