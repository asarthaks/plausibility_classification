{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a28baba-703d-46b5-9083-d6a2a801d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c72ea1e8-bbb5-4805-989a-78c496dabc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b6e8d3b-b1f0-4abc-8713-58fd5c880513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0328d790-8750-4766-bc92-ac62e300806f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '../../datasets/adept/train-dev-test-split/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../datasets/adept/train-dev-test-split/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a157adb2-742a-43ac-96c9-f4df0624229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d7e17f4-6b02-488a-a4c3-06084df5a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "adept_data_path = \"../../../datasets/adept/train-dev-test-split\"\n",
    "split = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1565a805-ea81-4d99-93c2-44c9343c89c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../datasets/adept/train-dev-test-split/train.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43madept_data_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../datasets/adept/train-dev-test-split/train.json'"
     ]
    }
   ],
   "source": [
    "train_data = json.load(open('{}/{}.json'.format(adept_data_path, split), 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89e5623-8fe8-4815-a11b-1f3368b732c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame(train_data)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b9e6b3-0098-4a2d-bbb7-907d165742a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_class_map = {0:\"Impossible\", 1:\"Less Likely\", 2:\"Equally Likely\", 3:\"More Likely\", 4:\"Necessarily True\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a016b8fa-755f-4fab-981c-8032a1e24ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_class_map.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c55742-f396-457c-9aaa-b67a42a0011f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['sentence2_preprocessed'] = df_train['sentence2'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "df_train['sentence2_preprocessed'] = df_train['sentence2_preprocessed'].map(lambda x: x.lower())\n",
    "df_train['class_label'] = df_train.label.map(lambda x: label_to_class_map[x])\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb31ed6b-e734-40f1-ae04-3d644129d764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We got this dataset for concreteness of 40k words (https://pubmed.ncbi.nlm.nih.gov/24142837/) from https://web.stanford.edu/class/linguist278/data/\n",
    "concreteness_df = pd.read_csv('../../../datasets/concreteness/Concreteness_ratings_Brysbaert_et_al_BRM.csv')\n",
    "concreteness_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784bf63a-ea2e-49b7-b6fa-68222779677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_concreteness_score_map = dict()\n",
    "for idx, row in concreteness_df.iterrows():\n",
    "    row = row.to_dict()\n",
    "    word_to_concreteness_score_map[row['Word']] = row['Conc.M']/5.0 # Normalizing to a scale of 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5eef04-632c-4bea-a8fd-ac1de97ad27d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_to_concreteness_score_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6baf8c30-513d-4b9d-97cc-fb571a09e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concreteness_score(word):\n",
    "    \"\"\"\n",
    "    Get the concreteness score of a word based on the Concreteness Ratings dataset.\n",
    "    \"\"\"\n",
    "    # If the word is not found in the dataset, return a default score of 0.5\n",
    "    return word_to_concreteness_score_map.get(word, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41a244c3-783f-4464-8aad-0998ec5a5c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_text_concreteness(text):\n",
    "    \"\"\"\n",
    "    Calculate the concreteness score for a given text.\n",
    "    \"\"\"\n",
    "    words = nltk.word_tokenize(text)\n",
    "    concreteness_scores = [get_concreteness_score(word) for word in words]\n",
    "    # Take the average concreteness score of all words in the text\n",
    "    return sum(concreteness_scores) / len(concreteness_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cc9123-912a-47f4-8000-7af7e9e272e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "text = \"the laws of the world can't stop him\"\n",
    "concreteness_score = calculate_text_concreteness(text)\n",
    "print(f\"Concreteness Score: {concreteness_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e242c3-0be5-4be5-934d-ce2adf258063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "text = \"car crash\"\n",
    "concreteness_score = calculate_text_concreteness(text)\n",
    "print(f\"Concreteness Score: {concreteness_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b98d4a-534f-4558-b9f0-b7525a3e0308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['concreteness_score'] = df_train.sentence2_preprocessed.apply(calculate_text_concreteness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8be043-4951-4da4-8325-5c977a806d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aeac54-5080-4c85-b8f2-14756ef15a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aff13f1-7ab5-4685-95c5-81dc1d261d34",
   "metadata": {},
   "source": [
    "# Fine Tuning Bert Base Uncased on ADEPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314eb2d5-7462-4b73-9331-8f4287391d6e",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafe14d4-5175-4bc0-8e2b-9f1f77956e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding, get_scheduler\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcb482a7-b289-4fce-9ef5-b9b85f07ace7",
   "metadata": {},
   "outputs": [],
   "source": [
    "adept_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66ff214-5ef6-4af0-8ca4-9ca96b65827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls '../../../datasets/adept/train-dev-test-split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54644933-cc35-4306-8224-09db821ad0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = \"train.json\"\n",
    "validation_split = \"val.json\"\n",
    "test_split = \"test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a645e70-ca3e-4d9e-b0ac-ab2aaaedd309",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_files = {\n",
    "    \"train\": \"{}/{}\".format(adept_data_path, train_split), \n",
    "    \"validation\": \"{}/{}\".format(adept_data_path, validation_split), \n",
    "    \"test\": \"{}/{}\".format(adept_data_path, test_split),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a5cad0-543e-4a48-a534-e03ead568db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adept_dataset = load_dataset(\"json\", data_files=data_files)\n",
    "adept_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ce803-b5d5-4f7e-b686-ba2d5562b27e",
   "metadata": {},
   "outputs": [],
   "source": [
    "adept_dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37de10af-b6c2-4e5b-a42a-d55e530958b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "adept_dataset['train'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93585e59-10ce-4629-a18c-bf8a82b9e075",
   "metadata": {},
   "source": [
    "These are the best params we got after fine tuning different models and parameter using optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d449483-b077-4b64-8f62-c26628d21b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'learning_rate': 3.660515504756857e-05,\n",
    " 'num_train_epochs': 3,\n",
    " 'model_name': \"microsoft/deberta-base\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd856392-129b-4ed3-8968-1581bb729f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = best_params['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa03946-023e-4730-99d7-7825b47b5530",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e6da47-3730-4107-ac17-77bef814247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=5, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dc8f47-070a-48fc-acbf-73beb908aa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence(item):\n",
    "    return tokenizer(item['sentence2'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b323805-73bb-4b8b-803d-39d705173a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = adept_dataset.map(tokenize_sentence, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbf8cfd-6c8a-4858-98a3-e61276cdb2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33bb7d11-a4f5-47e6-b915-87ec886cded3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = tokenized_dataset.remove_columns(['sentence1', 'sentence2', 'idx', 'modifier', 'noun'])\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "tokenized_dataset = tokenized_dataset.with_format(\"torch\")\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da9d9fb9-8f29-48c9-89c2-bfe2865f7fd2",
   "metadata": {},
   "source": [
    "#### Setting Up Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b0942a-4bcc-4d3a-93dd-1aa868c68168",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5f072d-2d8f-4b0f-8bdc-81d44e5cdb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f1c4c-2d22-42b8-b4e8-9752c5546211",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e6be41-cbd6-4568-a106-caaafae0ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_dataset['train'], batch_size=batch_size, shuffle=True, collate_fn=data_collator)\n",
    "validation_dataloader = DataLoader(tokenized_dataset['validation'], batch_size=batch_size, collate_fn=data_collator)\n",
    "test_dataloader = DataLoader(tokenized_dataset['test'], batch_size=batch_size, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c405044f-3e5c-444b-9bb5-5b7dbb788608",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d587af8-718f-4033-83fb-69dbfede5b19",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9802ba-3696-43d1-8e5e-2585aff7e81c",
   "metadata": {},
   "source": [
    "#### Setting up Optimizer with deacaying learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "058ecafe-5f09-4899-b7ab-1298bd630b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.adamw import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748f2537-8eb6-42f7-a636-a34063411ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=3.660515504756857e-05)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a69143-07d5-4576-8265-3506a871dbbb",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25ef78a-4180-4657-9a7e-f4b7651df897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_dataloader, num_epochs, optimizer):\n",
    "    num_training_steps = num_epochs*len(train_dataloader)\n",
    "    learning_rate_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "    model.train()\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k:v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            # calculating gradients\n",
    "            loss.backward()\n",
    "            # optimizing weights\n",
    "            optimizer.step()\n",
    "            # updating learning rate\n",
    "            learning_rate_scheduler.step()\n",
    "            # flushing gradients\n",
    "            optimizer.zero_grad()\n",
    "            # updating progress bar\n",
    "            progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716a7fe1-23f8-4540-af57-fb85ad0de117",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d606f2-8d07-424e-8764-fa8c7afafd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f134f08-4869-4847-98c4-0f3d0146c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load('accuracy')\n",
    "precision = evaluate.load('precision')\n",
    "recall = evaluate.load('recall')\n",
    "f1 = evaluate.load('f1')\n",
    "roc_auc =  evaluate.load(\"roc_auc\", \"multiclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a2fa04-d1b9-4bc1-952f-2b4e744e07fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6c700b-799e-4918-b970-b4ab1f9c0272",
   "metadata": {},
   "source": [
    "#### Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9867d79-9c56-4c32-a632-6741752d780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd67a1a-3737-40e5-893f-95ca31d6d33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03337545-99a6-4665-9c29-9e650ba3db2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader):\n",
    "    model.eval()\n",
    "    for batch in dataloader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        # Extract logits and predictions\n",
    "        logits = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "    \n",
    "        # Apply softmax to convert logits to probabilities\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        \n",
    "        # Extract probabilities for the positive class\n",
    "        positive_probabilities = probabilities\n",
    "    \n",
    "        # Update metrics for accuracy, precision, recall, and F1\n",
    "        for metric in metrics:\n",
    "            metric.add_batch(predictions=predictions, references=batch['labels'])\n",
    "    \n",
    "        # Update ROC AUC metric\n",
    "        roc_auc.add_batch(prediction_scores=positive_probabilities, references=batch['labels'])\n",
    "    \n",
    "    # # Compute metrics for accuracy, precision, recall, and F1\n",
    "    eval_dict = {}\n",
    "    \n",
    "    eval_dict.update(accuracy.compute())\n",
    "    eval_dict.update(precision.compute(average=\"macro\"))\n",
    "    eval_dict.update(recall.compute(average=\"macro\"))\n",
    "    eval_dict.update(f1.compute(average=\"macro\"))\n",
    "    eval_dict.update(roc_auc.compute(multi_class='ovo', average=\"macro\"))\n",
    "    return eval_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55faaa39-252a-42ca-b3ae-7c0d99fc430c",
   "metadata": {},
   "source": [
    "### Training and Testing the Models with different parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3cc3bf-3abf-4d9e-87b1-fe1fed4914de",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs_list = [1, 2, 3, 4, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8e2108-ada1-48d5-93e6-8ab77a677836",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_list = list()\n",
    "for num_epochs in num_epochs_list:\n",
    "    data_dict = dict()\n",
    "    data_dict['num_epochs'] = num_epochs\n",
    "    train_model(model, train_dataloader, num_epochs, optimizer)\n",
    "    validation_eval_dict = eval_model(model, validation_dataloader)\n",
    "    test_eval_dict = eval_model(model, test_dataloader)\n",
    "    for k, v in validation_eval_dict.items():\n",
    "        data_dict[\"validation_{}\".format(k)] = v\n",
    "    for k, v in test_eval_dict.items():\n",
    "        data_dict[\"test_{}\".format(k)] = v\n",
    "    print(data_dict)\n",
    "    eval_list.append(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0342a77b-8125-4b94-a01e-90860275f8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(eval_list)\n",
    "results_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c375af5f-b771-4644-945a-ef783bfa5fc0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
