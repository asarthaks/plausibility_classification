{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0fd0c000-4e3f-45e8-a818-d956f54a906b",
   "metadata": {},
   "source": [
    "# Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a28baba-703d-46b5-9083-d6a2a801d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c72ea1e8-bbb5-4805-989a-78c496dabc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b6e8d3b-b1f0-4abc-8713-58fd5c880513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0328d790-8750-4766-bc92-ac62e300806f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ls: cannot access '../datasets/adept/train-dev-test-split/': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!ls ../datasets/adept/train-dev-test-split/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a157adb2-742a-43ac-96c9-f4df0624229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d7e17f4-6b02-488a-a4c3-06084df5a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "adept_data_path = \"../../datasets/adept/train-dev-test-split\"\n",
    "split = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1565a805-ea81-4d99-93c2-44c9343c89c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = json.load(open('{}/{}.json'.format(adept_data_path, split), 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d89e5623-8fe8-4815-a11b-1f3368b732c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>modifier</th>\n",
       "      <th>noun</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The effect of sleeping is rejuvenation.</td>\n",
       "      <td>The effect of additional sleeping is rejuvenat...</td>\n",
       "      <td>additional</td>\n",
       "      <td>sleeping</td>\n",
       "      <td>3</td>\n",
       "      <td>13484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A toothbrush is for fresh breath.</td>\n",
       "      <td>A regular toothbrush is for fresh breath.</td>\n",
       "      <td>regular</td>\n",
       "      <td>toothbrush</td>\n",
       "      <td>2</td>\n",
       "      <td>2620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A scene is painted.</td>\n",
       "      <td>A negative scene is painted.</td>\n",
       "      <td>negative</td>\n",
       "      <td>scene</td>\n",
       "      <td>2</td>\n",
       "      <td>3324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A bone breaks a tooth.</td>\n",
       "      <td>An alleged bone breaks a tooth.</td>\n",
       "      <td>alleged</td>\n",
       "      <td>bone</td>\n",
       "      <td>2</td>\n",
       "      <td>10610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A trip causes a happening.</td>\n",
       "      <td>A fabulous trip causes a happening.</td>\n",
       "      <td>fabulous</td>\n",
       "      <td>trip</td>\n",
       "      <td>2</td>\n",
       "      <td>14917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sentence1  \\\n",
       "0  The effect of sleeping is rejuvenation.   \n",
       "1        A toothbrush is for fresh breath.   \n",
       "2                      A scene is painted.   \n",
       "3                   A bone breaks a tooth.   \n",
       "4               A trip causes a happening.   \n",
       "\n",
       "                                           sentence2    modifier        noun  \\\n",
       "0  The effect of additional sleeping is rejuvenat...  additional    sleeping   \n",
       "1          A regular toothbrush is for fresh breath.     regular  toothbrush   \n",
       "2                       A negative scene is painted.    negative       scene   \n",
       "3                    An alleged bone breaks a tooth.     alleged        bone   \n",
       "4                A fabulous trip causes a happening.    fabulous        trip   \n",
       "\n",
       "   label    idx  \n",
       "0      3  13484  \n",
       "1      2   2620  \n",
       "2      2   3324  \n",
       "3      2  10610  \n",
       "4      2  14917  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame(train_data)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95b9e6b3-0098-4a2d-bbb7-907d165742a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_class_map = {0:\"Impossible\", 1:\"Less Likely\", 2:\"Equally Likely\", 3:\"More Likely\", 4:\"Necessarily True\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a016b8fa-755f-4fab-981c-8032a1e24ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['Impossible', 'Less Likely', 'Equally Likely', 'More Likely', 'Necessarily True'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_class_map.values()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6dd2f6-10a5-4910-8669-8a719093994f",
   "metadata": {},
   "source": [
    "Preprocessing data to get concreteness scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15c55742-f396-457c-9aaa-b67a42a0011f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>modifier</th>\n",
       "      <th>noun</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "      <th>sentence2_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The effect of sleeping is rejuvenation.</td>\n",
       "      <td>The effect of additional sleeping is rejuvenat...</td>\n",
       "      <td>additional</td>\n",
       "      <td>sleeping</td>\n",
       "      <td>3</td>\n",
       "      <td>13484</td>\n",
       "      <td>the effect of additional sleeping is rejuvenation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A toothbrush is for fresh breath.</td>\n",
       "      <td>A regular toothbrush is for fresh breath.</td>\n",
       "      <td>regular</td>\n",
       "      <td>toothbrush</td>\n",
       "      <td>2</td>\n",
       "      <td>2620</td>\n",
       "      <td>a regular toothbrush is for fresh breath</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sentence1  \\\n",
       "0  The effect of sleeping is rejuvenation.   \n",
       "1        A toothbrush is for fresh breath.   \n",
       "\n",
       "                                           sentence2    modifier        noun  \\\n",
       "0  The effect of additional sleeping is rejuvenat...  additional    sleeping   \n",
       "1          A regular toothbrush is for fresh breath.     regular  toothbrush   \n",
       "\n",
       "   label    idx                             sentence2_preprocessed  \n",
       "0      3  13484  the effect of additional sleeping is rejuvenation  \n",
       "1      2   2620           a regular toothbrush is for fresh breath  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['sentence2_preprocessed'] = df_train['sentence2'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "df_train['sentence2_preprocessed'] = df_train['sentence2_preprocessed'].map(lambda x: x.lower())\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb31ed6b-e734-40f1-ae04-3d644129d764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Conc.SD</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent_known</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>Dom_Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roadsweeper</td>\n",
       "      <td>0</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traindriver</td>\n",
       "      <td>0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word  Bigram  Conc.M  Conc.SD  Unknown  Total  Percent_known  \\\n",
       "0  roadsweeper       0    4.85     0.37        1     27           0.96   \n",
       "1  traindriver       0    4.54     0.71        3     29           0.90   \n",
       "\n",
       "   SUBTLEX Dom_Pos  \n",
       "0        0       0  \n",
       "1        0       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We got this dataset for concreteness of 40k words (https://pubmed.ncbi.nlm.nih.gov/24142837/) from https://web.stanford.edu/class/linguist278/data/\n",
    "concreteness_df = pd.read_csv('../../datasets/concreteness/Concreteness_ratings_Brysbaert_et_al_BRM.csv')\n",
    "concreteness_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "784bf63a-ea2e-49b7-b6fa-68222779677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_concreteness_score_map = dict()\n",
    "for idx, row in concreteness_df.iterrows():\n",
    "    row = row.to_dict()\n",
    "    word_to_concreteness_score_map[row['Word']] = row['Conc.M']/5.0 # Normalizing to a scale of 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb5eef04-632c-4bea-a8fd-ac1de97ad27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39954"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_concreteness_score_map.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4613ac58-f6c2-43ed-9539-40002cbc531e",
   "metadata": {},
   "source": [
    "Some utility functions to get concreteness scores for the input sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6baf8c30-513d-4b9d-97cc-fb571a09e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concreteness_score(word):\n",
    "    \"\"\"\n",
    "    Get the concreteness score of a word based on the Concreteness Ratings dataset.\n",
    "    \"\"\"\n",
    "    # If the word is not found in the dataset, return a default score of 0.5\n",
    "    return round(word_to_concreteness_score_map.get(word, 0.5), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41a244c3-783f-4464-8aad-0998ec5a5c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_text_concreteness(text):\n",
    "    \"\"\"\n",
    "    Calculate the concreteness score for a given text.\n",
    "    \"\"\"\n",
    "    words = nltk.word_tokenize(text)\n",
    "    concreteness_scores = [get_concreteness_score(word) for word in words]\n",
    "    # Take the average concreteness score of all words in the text\n",
    "    return sum(concreteness_scores) / len(concreteness_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71a16f43-02b7-48cb-b573-24f688b9a0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_text_concreteness_sequence(text):\n",
    "    \"\"\"\n",
    "    Calculate the concreteness score for a given text.\n",
    "    \"\"\"\n",
    "    words = nltk.word_tokenize(text)\n",
    "    concreteness_scores = [get_concreteness_score(word) for word in words]\n",
    "    concreteness_scores = \" \".join([str(i) for i in concreteness_scores])\n",
    "    # Take the average concreteness score of all words in the text\n",
    "    return concreteness_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3cc9123-912a-47f4-8000-7af7e9e272e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concreteness Score: 0.5246666666666667\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "text = \"the laws of the world can't stop him\"\n",
    "concreteness_score = calculate_text_concreteness(text)\n",
    "print(f\"Concreteness Score: {concreteness_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b0e242c3-0be5-4be5-934d-ce2adf258063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concreteness Score: 0.868\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "text = \"car crash\"\n",
    "concreteness_score = calculate_text_concreteness(text)\n",
    "print(f\"Concreteness Score: {concreteness_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7a8ee2-b88a-4e2c-a746-e80939fdbc38",
   "metadata": {},
   "source": [
    "We are using concreteness score sequence because in the EDA we found that concreteness score can be a usefull factor in distinguishing whether the sentence is plausible or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "92b98d4a-534f-4558-b9f0-b7525a3e0308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['concreteness_score_sequence'] = df_train.sentence2_preprocessed.apply(calculate_text_concreteness_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9f8be043-4951-4da4-8325-5c977a806d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>modifier</th>\n",
       "      <th>noun</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "      <th>sentence2_preprocessed</th>\n",
       "      <th>concreteness_score_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The effect of sleeping is rejuvenation.</td>\n",
       "      <td>The effect of additional sleeping is rejuvenat...</td>\n",
       "      <td>additional</td>\n",
       "      <td>sleeping</td>\n",
       "      <td>3</td>\n",
       "      <td>13484</td>\n",
       "      <td>the effect of additional sleeping is rejuvenation</td>\n",
       "      <td>0.286 0.36 0.334 0.486 0.846 0.318 0.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A toothbrush is for fresh breath.</td>\n",
       "      <td>A regular toothbrush is for fresh breath.</td>\n",
       "      <td>regular</td>\n",
       "      <td>toothbrush</td>\n",
       "      <td>2</td>\n",
       "      <td>2620</td>\n",
       "      <td>a regular toothbrush is for fresh breath</td>\n",
       "      <td>0.292 0.48 1.0 0.318 0.326 0.394 0.872</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sentence1  \\\n",
       "0  The effect of sleeping is rejuvenation.   \n",
       "1        A toothbrush is for fresh breath.   \n",
       "\n",
       "                                           sentence2    modifier        noun  \\\n",
       "0  The effect of additional sleeping is rejuvenat...  additional    sleeping   \n",
       "1          A regular toothbrush is for fresh breath.     regular  toothbrush   \n",
       "\n",
       "   label    idx                             sentence2_preprocessed  \\\n",
       "0      3  13484  the effect of additional sleeping is rejuvenation   \n",
       "1      2   2620           a regular toothbrush is for fresh breath   \n",
       "\n",
       "               concreteness_score_sequence  \n",
       "0  0.286 0.36 0.334 0.486 0.846 0.318 0.42  \n",
       "1   0.292 0.48 1.0 0.318 0.326 0.394 0.872  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14aeac54-5080-4c85-b8f2-14756ef15a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12892, 8)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1bd731-60c4-48c4-afd9-28fbadc78915",
   "metadata": {},
   "source": [
    "Loading validation and test dataset and adding concreteness scores sequences for them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92adfbdf-d33c-4f14-bb58-582050d55989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1611, 6) (1612, 6)\n"
     ]
    }
   ],
   "source": [
    "df_validation = pd.DataFrame(json.load(open('{}/{}.json'.format(adept_data_path, \"val\"), 'r')))\n",
    "df_test = pd.DataFrame(json.load(open('{}/{}.json'.format(adept_data_path, \"test\"), 'r')))\n",
    "print(df_validation.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6888b95b-efa9-4b8b-8767-1c5468b51b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation['sentence2_preprocessed'] = df_validation['sentence2'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "df_validation['sentence2_preprocessed'] = df_validation['sentence2_preprocessed'].map(lambda x: x.lower())\n",
    "df_validation['concreteness_score_sequence'] = df_validation.sentence2_preprocessed.apply(calculate_text_concreteness_sequence)\n",
    "\n",
    "df_test['sentence2_preprocessed'] = df_test['sentence2'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "df_test['sentence2_preprocessed'] = df_test['sentence2_preprocessed'].map(lambda x: x.lower())\n",
    "df_test['concreteness_score_sequence'] = df_test.sentence2_preprocessed.apply(calculate_text_concreteness_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc1f9d85-b90f-4d2a-b138-5d6e2ea71844",
   "metadata": {},
   "source": [
    "### Artificial Dataset Combined"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62119db-637e-44af-8f38-3ab07b82c6f3",
   "metadata": {},
   "source": [
    "Loading artificially created dataset (using Llama 2 70B model). Checkout the notebook modelling/adept/ArtificialDataCreation - ADEPT.ipynb for more info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4c975816-ad8d-4546-8966-5f130a7ba9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artificial_train_combined = pd.read_csv('../../datasets/adept/generated-data/artificial_train_combined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8970e28d-96ee-4de8-814f-1d2d8f6d9522",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artificial_train_combined['sentence2_preprocessed'] = df_artificial_train_combined['sentence2'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "df_artificial_train_combined['sentence2_preprocessed'] = df_artificial_train_combined['sentence2_preprocessed'].map(lambda x: x.lower())\n",
    "df_artificial_train_combined['concreteness_score_sequence'] = df_artificial_train_combined.sentence2_preprocessed.apply(calculate_text_concreteness_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a01e590-2796-42c5-b7a9-c5aa53a5c466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>noun</th>\n",
       "      <th>modifier</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>idx</th>\n",
       "      <th>sentence2_preprocessed</th>\n",
       "      <th>concreteness_score_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dog</td>\n",
       "      <td>Happy</td>\n",
       "      <td>A happy dog wags its tail.</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a happy dog wags its tail</td>\n",
       "      <td>0.292 0.512 0.97 0.5 0.38 0.992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Building</td>\n",
       "      <td>Tall</td>\n",
       "      <td>A tall building casts a long shadow.</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>a tall building casts a long shadow</td>\n",
       "      <td>0.292 0.672 0.928 0.5 0.292 0.636 0.908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       noun modifier                             sentence2  label sentence1  \\\n",
       "0       Dog    Happy            A happy dog wags its tail.      4       NaN   \n",
       "1  Building     Tall  A tall building casts a long shadow.      4       NaN   \n",
       "\n",
       "   idx               sentence2_preprocessed  \\\n",
       "0  NaN            a happy dog wags its tail   \n",
       "1  NaN  a tall building casts a long shadow   \n",
       "\n",
       "               concreteness_score_sequence  \n",
       "0          0.292 0.512 0.97 0.5 0.38 0.992  \n",
       "1  0.292 0.672 0.928 0.5 0.292 0.636 0.908  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artificial_train_combined.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aff13f1-7ab5-4685-95c5-81dc1d261d34",
   "metadata": {},
   "source": [
    "# Fine Tuning Different Transformer Models using different strategies on ADEPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314eb2d5-7462-4b73-9331-8f4287391d6e",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fafe14d4-5175-4bc0-8e2b-9f1f77956e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding, get_scheduler\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fcb482a7-b289-4fce-9ef5-b9b85f07ace7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../../datasets/adept/train-dev-test-split'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adept_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb8a051-de82-4c27-8094-078d450701eb",
   "metadata": {},
   "source": [
    "Loading dataset in a format that can be used by huggingface transformers library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6a645e70-ca3e-4d9e-b0ac-ab2aaaedd309",
   "metadata": {},
   "outputs": [],
   "source": [
    "adept_dataset = DatasetDict({\n",
    "    'train': Dataset.from_pandas(df_train),\n",
    "    'validation': Dataset.from_pandas(df_validation),\n",
    "    'test': Dataset.from_pandas(df_test),\n",
    "    'artificial_train_combined': Dataset.from_pandas(df_artificial_train_combined)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "17a5cad0-543e-4a48-a534-e03ead568db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'modifier', 'noun', 'label', 'idx', 'sentence2_preprocessed', 'concreteness_score_sequence'],\n",
       "        num_rows: 12892\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'modifier', 'noun', 'label', 'idx', 'sentence2_preprocessed', 'concreteness_score_sequence'],\n",
       "        num_rows: 1611\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'modifier', 'noun', 'label', 'idx', 'sentence2_preprocessed', 'concreteness_score_sequence'],\n",
       "        num_rows: 1612\n",
       "    })\n",
       "    artificial_train_combined: Dataset({\n",
       "        features: ['noun', 'modifier', 'sentence2', 'label', 'sentence1', 'idx', 'sentence2_preprocessed', 'concreteness_score_sequence'],\n",
       "        num_rows: 13186\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adept_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "af5ce803-b5d5-4f7e-b686-ba2d5562b27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value(dtype='string', id=None),\n",
       " 'sentence2': Value(dtype='string', id=None),\n",
       " 'modifier': Value(dtype='string', id=None),\n",
       " 'noun': Value(dtype='string', id=None),\n",
       " 'label': Value(dtype='int64', id=None),\n",
       " 'idx': Value(dtype='int64', id=None),\n",
       " 'sentence2_preprocessed': Value(dtype='string', id=None),\n",
       " 'concreteness_score_sequence': Value(dtype='string', id=None)}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adept_dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "37de10af-b6c2-4e5b-a42a-d55e530958b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'A year is made up of 365 days.',\n",
       " 'sentence2': 'An outstanding year is made up of 365 days.',\n",
       " 'modifier': 'outstanding',\n",
       " 'noun': 'year',\n",
       " 'label': 2,\n",
       " 'idx': 2825,\n",
       " 'sentence2_preprocessed': 'an outstanding year is made up of 365 days',\n",
       " 'concreteness_score_sequence': '0.292 0.35 0.65 0.318 0.504 0.766 0.334 0.5 0.672'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adept_dataset['train'][10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93585e59-10ce-4629-a18c-bf8a82b9e075",
   "metadata": {},
   "source": [
    "These are the best params we got after fine tuning different models and parameter using optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9cf47ffe-34a4-40be-9e36-cc9e8a36b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.adamw import AdamW\n",
    "from torch.utils.data import DataLoader\n",
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7e284858-83f2-4b7e-8242-354e3c83d9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_KEEP = ['label', 'input_ids', 'token_type_ids', 'attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3e327952-a8c0-4ae9-9515-1660d80ed9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModellingExperiments:\n",
    "    def __init__(self, model_name, dataset, batch_size, learning_rate):\n",
    "        self.model_name = model_name\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.cols_to_keep = set(COLUMNS_TO_KEEP)\n",
    "        self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.data_collator = DataCollatorWithPadding(self.tokenizer)\n",
    "        \n",
    "    def tokenize_sentence_with_concreteness_score(self, item):\n",
    "        # We also tried using the concreteness score for the whole sentence as a feature input\n",
    "        # To implement that, we changed the source code of transformers library and changed the classification head manually \n",
    "        # So that we can accomodate that extra feature, but this method of encoding concreteness score sequence was giving better score\n",
    "        # Hence, we are using this only in the final experiments. You can check that experiment out in the following notebook:\n",
    "        # modelling/adept/experiments/FinalModellingWithConcretenessScore[DeBERTa] - ADEPT\n",
    "        return self.tokenizer(item['sentence2'], item['concreteness_score_sequence'], truncation=True)\n",
    "        \n",
    "    def tokenize_sentence(self, item):\n",
    "        # Normal tokenization\n",
    "        return self.tokenizer(item['sentence2'], truncation=True)\n",
    "        \n",
    "    def add_strategy_to_tokenizer_function_map(self):\n",
    "        # Mapping between strategy and the tokenization functions defined above\n",
    "        # Strategy refers to whether we are using normal tokenization or whether we want to do paired tokenization of \n",
    "        # both input sentence and the sequence of concreteness score for that sentence\n",
    "        self.strategy_to_tokenizer_function_map = dict()\n",
    "        self.strategy_to_tokenizer_function_map['normal_finetuning'] = self.tokenize_sentence_with_concreteness_score\n",
    "        self.strategy_to_tokenizer_function_map['concreteness_score_addition'] = self.tokenize_sentence\n",
    "        \n",
    "    def prepare_dataset(self, strategy):\n",
    "        # Here, we wull tokenize the dataset based on the strategy we are planning to use\n",
    "        self.strategy = strategy\n",
    "        self.add_strategy_to_tokenizer_function_map()\n",
    "        self.tokenized_dataset = self.dataset.map(self.strategy_to_tokenizer_function_map[self.strategy], batched=True)\n",
    "        current_cols = set(list(self.tokenized_dataset['train'].features.keys()))\n",
    "        self.tokenized_dataset = self.tokenized_dataset.remove_columns(list(current_cols - self.cols_to_keep))\n",
    "        self.tokenized_dataset = self.tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "        self.tokenized_dataset = self.tokenized_dataset.with_format(\"torch\")\n",
    "\n",
    "    def prepare_dataloaders(self, train_dataset_type):\n",
    "        # Here, we prepare the dataloaders, it also takes an argument named train_dataset_type which specified\n",
    "        # whether we want to use the original training data or the one combined with out artificially created dataset\n",
    "        self.train_dataset_type = train_dataset_type\n",
    "        self.train_dataloader = DataLoader(self.tokenized_dataset[self.train_dataset_type], batch_size=self.batch_size, shuffle=True, collate_fn=self.data_collator)\n",
    "        self.validation_dataloader = DataLoader(self.tokenized_dataset['validation'], batch_size=self.batch_size, collate_fn=self.data_collator)\n",
    "        self.test_dataloader = DataLoader(self.tokenized_dataset['test'], batch_size=self.batch_size, collate_fn=self.data_collator)\n",
    "\n",
    "    def init_model(self):\n",
    "        torch.manual_seed(4)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=5, ignore_mismatched_sizes=True)\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def setup_optimizer(self, num_epochs):\n",
    "        # Setting up optimizer and learning rate scheduler\n",
    "        self.num_epochs = num_epochs\n",
    "        self.optimizer = AdamW(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.num_training_steps = self.num_epochs*len(self.train_dataloader)\n",
    "        self.learning_rate_scheduler = get_scheduler(\"linear\", optimizer=self.optimizer, num_warmup_steps=0, num_training_steps=self.num_training_steps)\n",
    "    \n",
    "    def train_model(self):\n",
    "        # Training the Model\n",
    "        self.evaluation_results_list = list()\n",
    "        progress_bar = tqdm(range(self.num_training_steps))\n",
    "        for epoch in range(self.num_epochs):\n",
    "            self.model.train()\n",
    "            for batch in self.train_dataloader:\n",
    "                batch = {k:v.to(self.device) for k, v in batch.items()}\n",
    "                outputs = self.model(**batch)\n",
    "                loss = outputs.loss\n",
    "                # calculating gradients\n",
    "                loss.backward()\n",
    "                # optimizing weights\n",
    "                self.optimizer.step()\n",
    "                # updating learning rate\n",
    "                self.learning_rate_scheduler.step()\n",
    "                # flushing gradients\n",
    "                self.optimizer.zero_grad()\n",
    "                # updating progress bar\n",
    "                progress_bar.update(1)\n",
    "            # evaluating per epoch\n",
    "            self.eval_model(self.validation_dataloader)\n",
    "            eval_results = dict()\n",
    "            eval_results['epoch'] = epoch + 1\n",
    "            for k, v in self.eval_dict.items():\n",
    "                eval_results[\"validation_{}\".format(k)] = v\n",
    "            self.eval_model(self.test_dataloader)\n",
    "            for k, v in self.eval_dict.items():\n",
    "                eval_results[\"test_{}\".format(k)] = v\n",
    "            self.evaluation_results_list.append(eval_results)\n",
    "\n",
    "    def initialize_metrics(self):\n",
    "        # Initializing evaluation metrics\n",
    "        self.accuracy = evaluate.load('accuracy')\n",
    "        self.precision = evaluate.load('precision')\n",
    "        self.recall = evaluate.load('recall')\n",
    "        self.f1 = evaluate.load('f1')\n",
    "        self.roc_auc =  evaluate.load(\"roc_auc\", \"multiclass\")\n",
    "        self.metrics = [self.accuracy, self.precision, self.recall, self.f1]\n",
    "                \n",
    "    def eval_model(self, dataloader):\n",
    "        # Evaluating the model on different dataloaders\n",
    "        self.initialize_metrics()\n",
    "        self.model.eval()\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.to(self.device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**batch)\n",
    "            # Extract logits and predictions\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "            # Apply softmax to convert logits to probabilities\n",
    "            probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            \n",
    "            # Extract probabilities for the positive class\n",
    "            positive_probabilities = probabilities\n",
    "        \n",
    "            # Update metrics for accuracy, precision, recall, and F1\n",
    "            for metric in self.metrics:\n",
    "                metric.add_batch(predictions=predictions, references=batch['labels'])\n",
    "        \n",
    "            # Update ROC AUC metric\n",
    "            self.roc_auc.add_batch(prediction_scores=positive_probabilities, references=batch['labels'])\n",
    "        \n",
    "        # # Compute metrics for accuracy, precision, recall, and F1\n",
    "        self.eval_dict = {}\n",
    "        self.eval_dict.update(self.accuracy.compute())\n",
    "        self.eval_dict.update(self.precision.compute(average=\"macro\"))\n",
    "        self.eval_dict.update(self.recall.compute(average=\"macro\"))\n",
    "        self.eval_dict.update(self.f1.compute(average=\"macro\"))\n",
    "        self.eval_dict.update(self.roc_auc.compute(multi_class='ovo', average=\"macro\"))        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d265c6-ca58-4ec7-8680-472dd0e96795",
   "metadata": {},
   "source": [
    "# Running Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263f9724-8b9c-4ea4-8155-9a659b5960b8",
   "metadata": {},
   "source": [
    "Defining parameters on which we will run the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "10dda133-6db0-4dcc-8466-8255285f93a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_list = [\"microsoft/deberta-base\", \"facebook/bart-base\"]\n",
    "num_epochs = 4\n",
    "strategies_list = [\"concreteness_score_addition\", \"normal_finetuning\"]\n",
    "train_dataset_type_list = [\"train\", \"artificial_train_combined\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee27ab0-a62d-4285-8f24-dd118968018e",
   "metadata": {},
   "source": [
    "Defining static arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3949b6a3-df79-43dd-affa-2f0366e6c5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_args = dict()\n",
    "kw_args[\"dataset\"] = adept_dataset\n",
    "kw_args[\"batch_size\"] = 32\n",
    "# This learning rate was found when we were doing hyperparameter tuning of different models\n",
    "# To check out the hyperparameter tuning, look at the following notebook:\n",
    "# modelling/adept/experiments/FineTuningAndModelSelection - ADEPT.ipynb\n",
    "kw_args[\"learning_rate\"] = 3.660515504756857e-05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8528cd-6bc7-4ec2-9e37-26e99ccd48df",
   "metadata": {},
   "source": [
    "Running experiments in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "24e06ca0-fc46-4d51-9c48-c28527d561a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('result_dynamic_dict_final_random_seed_4.json', 'r') as openfile:\n",
    "    result_dynamic_dict = json.load(openfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0e1be96-cdf8-4db2-8169-0b2b9f96a7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 12892/12892 [00:00<00:00, 32020.83 examples/s]\n",
      "Map: 100%|██████████| 1611/1611 [00:00<00:00, 55202.64 examples/s]\n",
      "Map: 100%|██████████| 1612/1612 [00:00<00:00, 42416.94 examples/s]\n",
      "Map: 100%|██████████| 13186/13186 [00:00<00:00, 43613.25 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Model Training with the following Configurations: {'model_name': 'microsoft/deberta-base', 'strategy': 'concreteness_score_addition', 'train_dataset_type': 'train'}\n",
      "Model already trained, results are stored already!\n",
      "Evaluation Results: {'epoch': 1, 'validation_accuracy': 0.6927374301675978, 'validation_precision': 0.4218020040624624, 'validation_recall': 0.3559372710929617, 'validation_f1': 0.3768922810205211, 'validation_roc_auc': 0.7322247730008058, 'test_accuracy': 0.7109181141439206, 'test_precision': 0.43716666396861975, 'test_recall': 0.355651127194351, 'test_f1': 0.3810411090174126, 'test_roc_auc': 0.7480621093169341}\n",
      "Evaluation Results: {'epoch': 2, 'validation_accuracy': 0.6970825574177529, 'validation_precision': 0.42389880772256855, 'validation_recall': 0.3704935960884305, 'validation_f1': 0.3897601769441422, 'validation_roc_auc': 0.7471510359169014, 'test_accuracy': 0.716501240694789, 'test_precision': 0.44323430934064056, 'test_recall': 0.37569205891207735, 'test_f1': 0.39911016466674515, 'test_roc_auc': 0.7521232228941506}\n",
      "Evaluation Results: {'epoch': 3, 'validation_accuracy': 0.6952203600248293, 'validation_precision': 0.4348065391611574, 'validation_recall': 0.38111757381859046, 'validation_f1': 0.39849114414004394, 'validation_roc_auc': 0.7416702204465793, 'test_accuracy': 0.6972704714640199, 'test_precision': 0.4138699623541438, 'test_recall': 0.3711096128936415, 'test_f1': 0.38568488972615833, 'test_roc_auc': 0.7579992280838453}\n",
      "Evaluation Results: {'epoch': 4, 'validation_accuracy': 0.6759776536312849, 'validation_precision': 0.41413428206531655, 'validation_recall': 0.39330102647539245, 'validation_f1': 0.3980007288956302, 'validation_roc_auc': 0.748235621212072, 'test_accuracy': 0.6879652605459057, 'test_precision': 0.4026696303910632, 'test_recall': 0.3847691512430508, 'test_f1': 0.3896345834849244, 'test_roc_auc': 0.7618493948553722}\n",
      "**************************************************\n",
      "Model Training with the following Configurations: {'model_name': 'microsoft/deberta-base', 'strategy': 'concreteness_score_addition', 'train_dataset_type': 'artificial_train_combined'}\n",
      "Model already trained, results are stored already!\n",
      "Evaluation Results: {'epoch': 1, 'validation_accuracy': 0.7039106145251397, 'validation_precision': 0.46636108745345195, 'validation_recall': 0.2844471549676165, 'validation_f1': 0.3024495550597215, 'validation_roc_auc': 0.7255222363745157, 'test_accuracy': 0.7047146401985112, 'test_precision': 0.4636635811970497, 'test_recall': 0.2673219093360747, 'test_f1': 0.2824098002680195, 'test_roc_auc': 0.7261880371937802}\n",
      "Evaluation Results: {'epoch': 2, 'validation_accuracy': 0.7001862197392924, 'validation_precision': 0.4313624685543007, 'validation_recall': 0.37017312247760786, 'validation_f1': 0.3906041688156536, 'validation_roc_auc': 0.7544576455072842, 'test_accuracy': 0.7028535980148883, 'test_precision': 0.4307420925470572, 'test_recall': 0.37248031799696274, 'test_f1': 0.3916704786107582, 'test_roc_auc': 0.7577852008439887}\n",
      "Evaluation Results: {'epoch': 3, 'validation_accuracy': 0.7008069522036002, 'validation_precision': 0.43372110615727993, 'validation_recall': 0.35924115103188076, 'validation_f1': 0.3833207575524618, 'validation_roc_auc': 0.7504109898389111, 'test_accuracy': 0.7016129032258065, 'test_precision': 0.41672846830686383, 'test_recall': 0.35746604705958596, 'test_f1': 0.3790137377770292, 'test_roc_auc': 0.762922571283715}\n",
      "Evaluation Results: {'epoch': 4, 'validation_accuracy': 0.6852886405959032, 'validation_precision': 0.42041506738416123, 'validation_recall': 0.4033622116266014, 'validation_f1': 0.4086436760613049, 'validation_roc_auc': 0.7511751212301095, 'test_accuracy': 0.6755583126550868, 'test_precision': 0.39591511608405844, 'test_recall': 0.37608030012206095, 'test_f1': 0.3820738656746448, 'test_roc_auc': 0.7608685996900985}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 12892/12892 [00:00<00:00, 27778.76 examples/s]\n",
      "Map: 100%|██████████| 1611/1611 [00:00<00:00, 32111.62 examples/s]\n",
      "Map: 100%|██████████| 1612/1612 [00:00<00:00, 29213.19 examples/s]\n",
      "Map: 100%|██████████| 13186/13186 [00:00<00:00, 27302.39 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Model Training with the following Configurations: {'model_name': 'microsoft/deberta-base', 'strategy': 'normal_finetuning', 'train_dataset_type': 'train'}\n",
      "Model already trained, results are stored already!\n",
      "Evaluation Results: {'epoch': 1, 'validation_accuracy': 0.6641837368094351, 'validation_precision': 0.13283674736188703, 'validation_recall': 0.2, 'validation_f1': 0.15964192465497945, 'validation_roc_auc': 0.4925887407513775, 'test_accuracy': 0.6836228287841191, 'test_precision': 0.13672456575682382, 'test_recall': 0.2, 'test_f1': 0.1624170965364775, 'test_roc_auc': 0.5066870287818176}\n",
      "Evaluation Results: {'epoch': 2, 'validation_accuracy': 0.6641837368094351, 'validation_precision': 0.13283674736188703, 'validation_recall': 0.2, 'validation_f1': 0.15964192465497945, 'validation_roc_auc': 0.5096583369009977, 'test_accuracy': 0.6836228287841191, 'test_precision': 0.13672456575682382, 'test_recall': 0.2, 'test_f1': 0.1624170965364775, 'test_roc_auc': 0.5172044720802876}\n",
      "Evaluation Results: {'epoch': 3, 'validation_accuracy': 0.6641837368094351, 'validation_precision': 0.13283674736188703, 'validation_recall': 0.2, 'validation_f1': 0.15964192465497945, 'validation_roc_auc': 0.505349078749955, 'test_accuracy': 0.6836228287841191, 'test_precision': 0.13672456575682382, 'test_recall': 0.2, 'test_f1': 0.1624170965364775, 'test_roc_auc': 0.4953449943917754}\n",
      "Evaluation Results: {'epoch': 4, 'validation_accuracy': 0.6641837368094351, 'validation_precision': 0.13283674736188703, 'validation_recall': 0.2, 'validation_f1': 0.15964192465497945, 'validation_roc_auc': 0.516211649922823, 'test_accuracy': 0.6836228287841191, 'test_precision': 0.13672456575682382, 'test_recall': 0.2, 'test_f1': 0.1624170965364775, 'test_roc_auc': 0.5157325885822553}\n",
      "**************************************************\n",
      "Model Training with the following Configurations: {'model_name': 'microsoft/deberta-base', 'strategy': 'normal_finetuning', 'train_dataset_type': 'artificial_train_combined'}\n",
      "Model already trained, results are stored already!\n",
      "Evaluation Results: {'epoch': 1, 'validation_accuracy': 0.6641837368094351, 'validation_precision': 0.13283674736188703, 'validation_recall': 0.2, 'validation_f1': 0.15964192465497945, 'validation_roc_auc': 0.6165894658085169, 'test_accuracy': 0.6836228287841191, 'test_precision': 0.13672456575682382, 'test_recall': 0.2, 'test_f1': 0.1624170965364775, 'test_roc_auc': 0.6273248596128914}\n",
      "Evaluation Results: {'epoch': 2, 'validation_accuracy': 0.6846679081315953, 'validation_precision': 0.31039490257566216, 'validation_recall': 0.2748058938449449, 'validation_f1': 0.2746759570155926, 'validation_roc_auc': 0.6959619673936746, 'test_accuracy': 0.6823821339950372, 'test_precision': 0.2946252088826346, 'test_recall': 0.2653234177868652, 'test_f1': 0.26474779389471337, 'test_roc_auc': 0.6739537012060015}\n",
      "Evaluation Results: {'epoch': 3, 'validation_accuracy': 0.7063935443823712, 'validation_precision': 0.44152247365284125, 'validation_recall': 0.3235349984615543, 'validation_f1': 0.3355544508842557, 'validation_roc_auc': 0.7025269399741252, 'test_accuracy': 0.705955334987593, 'test_precision': 0.43663118974394416, 'test_recall': 0.3102390563351434, 'test_f1': 0.3187718336599571, 'test_roc_auc': 0.7143608138524307}\n",
      "Evaluation Results: {'epoch': 4, 'validation_accuracy': 0.6989447548106766, 'validation_precision': 0.4224931129839001, 'validation_recall': 0.3815299063116149, 'validation_f1': 0.3963069245486375, 'validation_roc_auc': 0.7026333772450581, 'test_accuracy': 0.6947890818858561, 'test_precision': 0.4053880441760006, 'test_recall': 0.3540037620310231, 'test_f1': 0.37207936495225263, 'test_roc_auc': 0.7074599270943533}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 12892/12892 [00:00<00:00, 66126.59 examples/s]\n",
      "Map: 100%|██████████| 1611/1611 [00:00<00:00, 38439.14 examples/s]\n",
      "Map: 100%|██████████| 1612/1612 [00:00<00:00, 73348.79 examples/s]\n",
      "Map: 100%|██████████| 13186/13186 [00:00<00:00, 53923.18 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Model Training with the following Configurations: {'model_name': 'facebook/bart-base', 'strategy': 'concreteness_score_addition', 'train_dataset_type': 'train'}\n",
      "Model already trained, results are stored already!\n",
      "Evaluation Results: {'epoch': 1, 'validation_accuracy': 0.7070142768466791, 'validation_precision': 0.36399443772173024, 'validation_recall': 0.3070603925335841, 'validation_f1': 0.31791435746436125, 'validation_roc_auc': 0.7120372589799651, 'test_accuracy': 0.7053349875930521, 'test_precision': 0.3375714285714286, 'test_recall': 0.28835432254569604, 'test_f1': 0.29675173294200463, 'test_roc_auc': 0.7358062994449799}\n",
      "Evaluation Results: {'epoch': 2, 'validation_accuracy': 0.6883923029174426, 'validation_precision': 0.42029394992688457, 'validation_recall': 0.3541590503336739, 'validation_f1': 0.36837985688588315, 'validation_roc_auc': 0.7197915116873297, 'test_accuracy': 0.7084367245657568, 'test_precision': 0.4364602969860095, 'test_recall': 0.36839131874408065, 'test_f1': 0.38423817316203734, 'test_roc_auc': 0.7576000918453699}\n",
      "Evaluation Results: {'epoch': 3, 'validation_accuracy': 0.6983240223463687, 'validation_precision': 0.4253922369292879, 'validation_recall': 0.3534225852239283, 'validation_f1': 0.3761001845140882, 'validation_roc_auc': 0.7434105313036007, 'test_accuracy': 0.7258064516129032, 'test_precision': 0.46521003526637605, 'test_recall': 0.36869564678240196, 'test_f1': 0.3984377651786271, 'test_roc_auc': 0.7754112587794413}\n",
      "Evaluation Results: {'epoch': 4, 'validation_accuracy': 0.6939788950962136, 'validation_precision': 0.4213673548780063, 'validation_recall': 0.3718602127493512, 'validation_f1': 0.3886412778342949, 'validation_roc_auc': 0.7386276121148969, 'test_accuracy': 0.7127791563275434, 'test_precision': 0.4404403174229829, 'test_recall': 0.38161343229120803, 'test_f1': 0.4008671468979118, 'test_roc_auc': 0.7730985527938727}\n",
      "**************************************************\n",
      "Model Training with the following Configurations: {'model_name': 'facebook/bart-base', 'strategy': 'concreteness_score_addition', 'train_dataset_type': 'artificial_train_combined'}\n",
      "Model already trained, results are stored already!\n",
      "Evaluation Results: {'epoch': 1, 'validation_accuracy': 0.685909373060211, 'validation_precision': 0.35540669097827815, 'validation_recall': 0.2518469483520096, 'validation_f1': 0.2523205583542464, 'validation_roc_auc': 0.7087743402881733, 'test_accuracy': 0.7022332506203474, 'test_precision': 0.36700296046903114, 'test_recall': 0.251662523202682, 'test_f1': 0.2547913818086571, 'test_roc_auc': 0.7234334931822304}\n",
      "Evaluation Results: {'epoch': 2, 'validation_accuracy': 0.707635009310987, 'validation_precision': 0.4489642022336649, 'validation_recall': 0.34511897830776583, 'validation_f1': 0.3737062294396347, 'validation_roc_auc': 0.7321303594919664, 'test_accuracy': 0.7115384615384616, 'test_precision': 0.44092423045556445, 'test_recall': 0.3321934818370606, 'test_f1': 0.3616471875312989, 'test_roc_auc': 0.7486458460108134}\n",
      "Evaluation Results: {'epoch': 3, 'validation_accuracy': 0.6778398510242085, 'validation_precision': 0.4167820994414326, 'validation_recall': 0.3850412454727066, 'validation_f1': 0.3872696688004399, 'validation_roc_auc': 0.741753352359449, 'test_accuracy': 0.6885856079404467, 'test_precision': 0.43068810383605954, 'test_recall': 0.37404479075073416, 'test_f1': 0.3817452721778344, 'test_roc_auc': 0.7483801462945872}\n",
      "Evaluation Results: {'epoch': 4, 'validation_accuracy': 0.6927374301675978, 'validation_precision': 0.4223914649282835, 'validation_recall': 0.3774685279905435, 'validation_f1': 0.3907042365153489, 'validation_roc_auc': 0.743696937722736, 'test_accuracy': 0.705955334987593, 'test_precision': 0.4398475314089447, 'test_recall': 0.37439961558382395, 'test_f1': 0.394189741411649, 'test_roc_auc': 0.7456736072864923}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 12892/12892 [00:00<00:00, 40285.02 examples/s]\n",
      "Map: 100%|██████████| 1611/1611 [00:00<00:00, 9955.57 examples/s]\n",
      "Map: 100%|██████████| 1612/1612 [00:00<00:00, 43072.22 examples/s]\n",
      "Map: 100%|██████████| 13186/13186 [00:00<00:00, 39848.30 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Model Training with the following Configurations: {'model_name': 'facebook/bart-base', 'strategy': 'normal_finetuning', 'train_dataset_type': 'train'}\n",
      "Model already trained, results are stored already!\n",
      "Evaluation Results: {'epoch': 1, 'validation_accuracy': 0.7039106145251397, 'validation_precision': 0.35093410985497314, 'validation_recall': 0.29744720315989026, 'validation_f1': 0.30546865069415696, 'validation_roc_auc': 0.6933118356398368, 'test_accuracy': 0.7047146401985112, 'test_precision': 0.332382548007548, 'test_recall': 0.2815780832259709, 'test_f1': 0.2887814215915707, 'test_roc_auc': 0.6762599152322426}\n",
      "Evaluation Results: {'epoch': 2, 'validation_accuracy': 0.6964618249534451, 'validation_precision': 0.4232432628827786, 'validation_recall': 0.35148362068853234, 'validation_f1': 0.3724079161712285, 'validation_roc_auc': 0.7171933773532457, 'test_accuracy': 0.7096774193548387, 'test_precision': 0.440907639772888, 'test_recall': 0.3640966103764508, 'test_f1': 0.386368529743842, 'test_roc_auc': 0.7585966290902519}\n",
      "Evaluation Results: {'epoch': 3, 'validation_accuracy': 0.7051520794537555, 'validation_precision': 0.44115638054338174, 'validation_recall': 0.3661445700081947, 'validation_f1': 0.3885802099597752, 'validation_roc_auc': 0.7307552994070688, 'test_accuracy': 0.7214640198511166, 'test_precision': 0.46506788983877223, 'test_recall': 0.3656290357184922, 'test_f1': 0.39376886164998004, 'test_roc_auc': 0.7737514940947146}\n",
      "Evaluation Results: {'epoch': 4, 'validation_accuracy': 0.6964618249534451, 'validation_precision': 0.4261663910847358, 'validation_recall': 0.37346463273229247, 'validation_f1': 0.3923783487589373, 'validation_roc_auc': 0.7326235369651488, 'test_accuracy': 0.7220843672456576, 'test_precision': 0.4548382381187325, 'test_recall': 0.3914894831730128, 'test_f1': 0.41518807140360925, 'test_roc_auc': 0.776405633543798}\n",
      "**************************************************\n",
      "Model Training with the following Configurations: {'model_name': 'facebook/bart-base', 'strategy': 'normal_finetuning', 'train_dataset_type': 'artificial_train_combined'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.dense.weight', 'classification_head.out_proj.weight', 'classification_head.dense.bias', 'classification_head.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "  0%|          | 0/1652 [00:00<?, ?it/s]You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 1652/1652 [08:48<00:00,  3.12it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Results: {'epoch': 1, 'validation_accuracy': 0.6896337678460583, 'validation_precision': 0.42494599190184346, 'validation_recall': 0.26487257451843044, 'validation_f1': 0.2738568214250596, 'validation_roc_auc': 0.6824714796150582, 'test_accuracy': 0.7009925558312655, 'test_precision': 0.42362675995952737, 'test_recall': 0.2583131869086401, 'test_f1': 0.2657690587570671, 'test_roc_auc': 0.7135223173681743}\n",
      "Evaluation Results: {'epoch': 2, 'validation_accuracy': 0.6890130353817505, 'validation_precision': 0.41081509094399615, 'validation_recall': 0.34014347671486594, 'validation_f1': 0.3608828302705508, 'validation_roc_auc': 0.7217884808086161, 'test_accuracy': 0.7078163771712159, 'test_precision': 0.45065748660160543, 'test_recall': 0.35938309925669637, 'test_f1': 0.3878910962055507, 'test_roc_auc': 0.737850820834112}\n",
      "Evaluation Results: {'epoch': 3, 'validation_accuracy': 0.6399751707014277, 'validation_precision': 0.396843273464405, 'validation_recall': 0.3683321505686939, 'validation_f1': 0.36546069989478147, 'validation_roc_auc': 0.7393613790412739, 'test_accuracy': 0.6600496277915633, 'test_precision': 0.416617019788826, 'test_recall': 0.38104806653286166, 'test_f1': 0.38090260887332955, 'test_roc_auc': 0.7497839047121518}\n",
      "Evaluation Results: {'epoch': 4, 'validation_accuracy': 0.6921166977032899, 'validation_precision': 0.42086984311201103, 'validation_recall': 0.37416944323295814, 'validation_f1': 0.390069304574433, 'validation_roc_auc': 0.7415441982965765, 'test_accuracy': 0.7040942928039702, 'test_precision': 0.4425770229894229, 'test_recall': 0.3865735016572735, 'test_f1': 0.4046415797736948, 'test_roc_auc': 0.7511411958459342}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result_list = list()\n",
    "for model_name in model_name_list:\n",
    "    # Setting Model Name\n",
    "    kw_args[\"model_name\"] = model_name\n",
    "    # Initializing ModellingExperiments Object\n",
    "    modelling_obj = ModellingExperiments(**kw_args)\n",
    "    for strategy in strategies_list:\n",
    "        # Preparing dataset for a specific strategy\n",
    "        modelling_obj.prepare_dataset(strategy=strategy)\n",
    "        for train_dataset_type in train_dataset_type_list:\n",
    "            # Preparing data loaders\n",
    "            modelling_obj.prepare_dataloaders(train_dataset_type=train_dataset_type)\n",
    "            print(\"*\"*50)\n",
    "            # Initializing dictionary for storing results\n",
    "            result_dict = dict()\n",
    "            result_dict[\"model_name\"] = model_name\n",
    "            result_dict[\"strategy\"] = strategy\n",
    "            result_dict[\"train_dataset_type\"] = train_dataset_type\n",
    "            print(\"Model Training with the following Configurations: {}\".format(result_dict))\n",
    "            unique_key = \"#\".join(str(i) for i in list(result_dict.values()))\n",
    "            if not result_dynamic_dict.get(unique_key):\n",
    "                result_dynamic_dict[unique_key] = dict()\n",
    "                # initializing model\n",
    "                modelling_obj.init_model()\n",
    "                # For a specic num_epochs variable, we are setting up the optimizers\n",
    "                modelling_obj.setup_optimizer(num_epochs=num_epochs)\n",
    "                # Now, we are training the model\n",
    "                modelling_obj.train_model()\n",
    "                # Saving evaluated results\n",
    "                evaluation_results_list = modelling_obj.evaluation_results_list\n",
    "                for evaluation_results in evaluation_results_list:\n",
    "                    print(\"Evaluation Results: {}\".format(evaluation_results))\n",
    "                    result_dict.update(evaluation_results)\n",
    "                    result_list.append(result_dict)\n",
    "                # Updating the stored file\n",
    "                result_dynamic_dict[unique_key] = evaluation_results_list\n",
    "                # Storing the updated result file\n",
    "                with open('result_dynamic_dict_final_random_seed_4.json', 'w', encoding='utf-8') as f:\n",
    "                    json.dump(result_dynamic_dict, f, ensure_ascii=False, indent=4)\n",
    "            else:\n",
    "                print(\"Model already trained, results are stored already!\")\n",
    "                for res in result_dynamic_dict[unique_key]:\n",
    "                    print(\"Evaluation Results: {}\".format(res))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5993819f-aab9-4bd1-8c88-8ed3bc756427",
   "metadata": {},
   "source": [
    "We are done with the experiments, now, let's take a look at the results. First, we will have to convert our dynamic results dictionary to a more readable format. Let's do that first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "da110aa1-53e8-415d-836d-a2d7a03fcc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = list()\n",
    "for k, v in  result_dynamic_dict.items():\n",
    "    model_name, strategy, train_dataset_type = k.split(\"#\")\n",
    "    for item in v:\n",
    "        result_dict = dict()\n",
    "        result_dict['model_name'] = model_name\n",
    "        result_dict['strategy'] = strategy\n",
    "        result_dict['train_dataset_type'] = train_dataset_type\n",
    "        result_dict.update(item)\n",
    "        result_list.append(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "28d9053d-8cbc-4a7e-89f2-e064ac0c2ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>strategy</th>\n",
       "      <th>train_dataset_type</th>\n",
       "      <th>epoch</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>validation_precision</th>\n",
       "      <th>validation_recall</th>\n",
       "      <th>validation_f1</th>\n",
       "      <th>validation_roc_auc</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>microsoft/deberta-base</td>\n",
       "      <td>concreteness_score_addition</td>\n",
       "      <td>train</td>\n",
       "      <td>1</td>\n",
       "      <td>0.692737</td>\n",
       "      <td>0.421802</td>\n",
       "      <td>0.355937</td>\n",
       "      <td>0.376892</td>\n",
       "      <td>0.732225</td>\n",
       "      <td>0.710918</td>\n",
       "      <td>0.437167</td>\n",
       "      <td>0.355651</td>\n",
       "      <td>0.381041</td>\n",
       "      <td>0.748062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>microsoft/deberta-base</td>\n",
       "      <td>concreteness_score_addition</td>\n",
       "      <td>train</td>\n",
       "      <td>2</td>\n",
       "      <td>0.697083</td>\n",
       "      <td>0.423899</td>\n",
       "      <td>0.370494</td>\n",
       "      <td>0.389760</td>\n",
       "      <td>0.747151</td>\n",
       "      <td>0.716501</td>\n",
       "      <td>0.443234</td>\n",
       "      <td>0.375692</td>\n",
       "      <td>0.399110</td>\n",
       "      <td>0.752123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>microsoft/deberta-base</td>\n",
       "      <td>concreteness_score_addition</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>0.695220</td>\n",
       "      <td>0.434807</td>\n",
       "      <td>0.381118</td>\n",
       "      <td>0.398491</td>\n",
       "      <td>0.741670</td>\n",
       "      <td>0.697270</td>\n",
       "      <td>0.413870</td>\n",
       "      <td>0.371110</td>\n",
       "      <td>0.385685</td>\n",
       "      <td>0.757999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>microsoft/deberta-base</td>\n",
       "      <td>concreteness_score_addition</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>0.675978</td>\n",
       "      <td>0.414134</td>\n",
       "      <td>0.393301</td>\n",
       "      <td>0.398001</td>\n",
       "      <td>0.748236</td>\n",
       "      <td>0.687965</td>\n",
       "      <td>0.402670</td>\n",
       "      <td>0.384769</td>\n",
       "      <td>0.389635</td>\n",
       "      <td>0.761849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microsoft/deberta-base</td>\n",
       "      <td>concreteness_score_addition</td>\n",
       "      <td>artificial_train_combined</td>\n",
       "      <td>1</td>\n",
       "      <td>0.703911</td>\n",
       "      <td>0.466361</td>\n",
       "      <td>0.284447</td>\n",
       "      <td>0.302450</td>\n",
       "      <td>0.725522</td>\n",
       "      <td>0.704715</td>\n",
       "      <td>0.463664</td>\n",
       "      <td>0.267322</td>\n",
       "      <td>0.282410</td>\n",
       "      <td>0.726188</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_name                     strategy  \\\n",
       "0  microsoft/deberta-base  concreteness_score_addition   \n",
       "1  microsoft/deberta-base  concreteness_score_addition   \n",
       "2  microsoft/deberta-base  concreteness_score_addition   \n",
       "3  microsoft/deberta-base  concreteness_score_addition   \n",
       "4  microsoft/deberta-base  concreteness_score_addition   \n",
       "\n",
       "          train_dataset_type  epoch  validation_accuracy  \\\n",
       "0                      train      1             0.692737   \n",
       "1                      train      2             0.697083   \n",
       "2                      train      3             0.695220   \n",
       "3                      train      4             0.675978   \n",
       "4  artificial_train_combined      1             0.703911   \n",
       "\n",
       "   validation_precision  validation_recall  validation_f1  validation_roc_auc  \\\n",
       "0              0.421802           0.355937       0.376892            0.732225   \n",
       "1              0.423899           0.370494       0.389760            0.747151   \n",
       "2              0.434807           0.381118       0.398491            0.741670   \n",
       "3              0.414134           0.393301       0.398001            0.748236   \n",
       "4              0.466361           0.284447       0.302450            0.725522   \n",
       "\n",
       "   test_accuracy  test_precision  test_recall   test_f1  test_roc_auc  \n",
       "0       0.710918        0.437167     0.355651  0.381041      0.748062  \n",
       "1       0.716501        0.443234     0.375692  0.399110      0.752123  \n",
       "2       0.697270        0.413870     0.371110  0.385685      0.757999  \n",
       "3       0.687965        0.402670     0.384769  0.389635      0.761849  \n",
       "4       0.704715        0.463664     0.267322  0.282410      0.726188  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(result_list)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ae1277d-25b0-4f44-a6da-4e4063364b8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 14)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4201baae-beeb-4339-b739-de9794b2abe2",
   "metadata": {},
   "source": [
    "Now, let's take a look at the top three models with best test ROC-AUC score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd0d2ac4-5a0e-4335-8bfd-af473d102e52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>strategy</th>\n",
       "      <th>train_dataset_type</th>\n",
       "      <th>epoch</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>validation_precision</th>\n",
       "      <th>validation_recall</th>\n",
       "      <th>validation_f1</th>\n",
       "      <th>validation_roc_auc</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>facebook/bart-base</td>\n",
       "      <td>normal_finetuning</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>0.696462</td>\n",
       "      <td>0.426166</td>\n",
       "      <td>0.373465</td>\n",
       "      <td>0.392378</td>\n",
       "      <td>0.732624</td>\n",
       "      <td>0.722084</td>\n",
       "      <td>0.454838</td>\n",
       "      <td>0.391489</td>\n",
       "      <td>0.415188</td>\n",
       "      <td>0.776406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>facebook/bart-base</td>\n",
       "      <td>concreteness_score_addition</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>0.698324</td>\n",
       "      <td>0.425392</td>\n",
       "      <td>0.353423</td>\n",
       "      <td>0.376100</td>\n",
       "      <td>0.743411</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.465210</td>\n",
       "      <td>0.368696</td>\n",
       "      <td>0.398438</td>\n",
       "      <td>0.775411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>facebook/bart-base</td>\n",
       "      <td>normal_finetuning</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>0.705152</td>\n",
       "      <td>0.441156</td>\n",
       "      <td>0.366145</td>\n",
       "      <td>0.388580</td>\n",
       "      <td>0.730755</td>\n",
       "      <td>0.721464</td>\n",
       "      <td>0.465068</td>\n",
       "      <td>0.365629</td>\n",
       "      <td>0.393769</td>\n",
       "      <td>0.773751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name                     strategy train_dataset_type  epoch  \\\n",
       "27  facebook/bart-base            normal_finetuning              train      4   \n",
       "18  facebook/bart-base  concreteness_score_addition              train      3   \n",
       "26  facebook/bart-base            normal_finetuning              train      3   \n",
       "\n",
       "    validation_accuracy  validation_precision  validation_recall  \\\n",
       "27             0.696462              0.426166           0.373465   \n",
       "18             0.698324              0.425392           0.353423   \n",
       "26             0.705152              0.441156           0.366145   \n",
       "\n",
       "    validation_f1  validation_roc_auc  test_accuracy  test_precision  \\\n",
       "27       0.392378            0.732624       0.722084        0.454838   \n",
       "18       0.376100            0.743411       0.725806        0.465210   \n",
       "26       0.388580            0.730755       0.721464        0.465068   \n",
       "\n",
       "    test_recall   test_f1  test_roc_auc  \n",
       "27     0.391489  0.415188      0.776406  \n",
       "18     0.368696  0.398438      0.775411  \n",
       "26     0.365629  0.393769      0.773751  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by=['test_roc_auc'], ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e19121-38cc-4c12-a477-ead280ee014e",
   "metadata": {},
   "source": [
    "Here, we can see that BART Base model with normal finetuning and on original training set is getting .776406 ROC-AUC. Which is good.\n",
    "We can also see that the BART model in which we have added concreteness score as another input sequence, is not much behind it.\n",
    "Also, the test accuracy for 5 label classification is better than the one mentioned in the ADEPT paper."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11306909-3f7f-4ffa-926d-f624972cc5fc",
   "metadata": {},
   "source": [
    "Now, let's take a look at top three models with best test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5141b0e7-c6d4-43d6-b07e-0c5497a18b6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>strategy</th>\n",
       "      <th>train_dataset_type</th>\n",
       "      <th>epoch</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>validation_precision</th>\n",
       "      <th>validation_recall</th>\n",
       "      <th>validation_f1</th>\n",
       "      <th>validation_roc_auc</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>facebook/bart-base</td>\n",
       "      <td>concreteness_score_addition</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>0.698324</td>\n",
       "      <td>0.425392</td>\n",
       "      <td>0.353423</td>\n",
       "      <td>0.376100</td>\n",
       "      <td>0.743411</td>\n",
       "      <td>0.725806</td>\n",
       "      <td>0.465210</td>\n",
       "      <td>0.368696</td>\n",
       "      <td>0.398438</td>\n",
       "      <td>0.775411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>facebook/bart-base</td>\n",
       "      <td>normal_finetuning</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>0.696462</td>\n",
       "      <td>0.426166</td>\n",
       "      <td>0.373465</td>\n",
       "      <td>0.392378</td>\n",
       "      <td>0.732624</td>\n",
       "      <td>0.722084</td>\n",
       "      <td>0.454838</td>\n",
       "      <td>0.391489</td>\n",
       "      <td>0.415188</td>\n",
       "      <td>0.776406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>facebook/bart-base</td>\n",
       "      <td>normal_finetuning</td>\n",
       "      <td>train</td>\n",
       "      <td>3</td>\n",
       "      <td>0.705152</td>\n",
       "      <td>0.441156</td>\n",
       "      <td>0.366145</td>\n",
       "      <td>0.388580</td>\n",
       "      <td>0.730755</td>\n",
       "      <td>0.721464</td>\n",
       "      <td>0.465068</td>\n",
       "      <td>0.365629</td>\n",
       "      <td>0.393769</td>\n",
       "      <td>0.773751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            model_name                     strategy train_dataset_type  epoch  \\\n",
       "18  facebook/bart-base  concreteness_score_addition              train      3   \n",
       "27  facebook/bart-base            normal_finetuning              train      4   \n",
       "26  facebook/bart-base            normal_finetuning              train      3   \n",
       "\n",
       "    validation_accuracy  validation_precision  validation_recall  \\\n",
       "18             0.698324              0.425392           0.353423   \n",
       "27             0.696462              0.426166           0.373465   \n",
       "26             0.705152              0.441156           0.366145   \n",
       "\n",
       "    validation_f1  validation_roc_auc  test_accuracy  test_precision  \\\n",
       "18       0.376100            0.743411       0.725806        0.465210   \n",
       "27       0.392378            0.732624       0.722084        0.454838   \n",
       "26       0.388580            0.730755       0.721464        0.465068   \n",
       "\n",
       "    test_recall   test_f1  test_roc_auc  \n",
       "18     0.368696  0.398438      0.775411  \n",
       "27     0.391489  0.415188      0.776406  \n",
       "26     0.365629  0.393769      0.773751  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values(by=['test_accuracy'], ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e425a1-bbce-41ba-99e6-bfef3470b6fa",
   "metadata": {},
   "source": [
    "Here, the our BART model with concreteness score sequence is giving better results in accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9aa7f26-e2cf-44a8-9d4b-d1bd3c21c7f4",
   "metadata": {},
   "source": [
    "Now, let's take a look at models which used artificially created dataset. Let's see how they are performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74b64f34-2cba-4e46-b51c-11198f06f8e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>strategy</th>\n",
       "      <th>train_dataset_type</th>\n",
       "      <th>epoch</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>validation_precision</th>\n",
       "      <th>validation_recall</th>\n",
       "      <th>validation_f1</th>\n",
       "      <th>validation_roc_auc</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>microsoft/deberta-base</td>\n",
       "      <td>concreteness_score_addition</td>\n",
       "      <td>artificial_train_combined</td>\n",
       "      <td>3</td>\n",
       "      <td>0.700807</td>\n",
       "      <td>0.433721</td>\n",
       "      <td>0.359241</td>\n",
       "      <td>0.383321</td>\n",
       "      <td>0.750411</td>\n",
       "      <td>0.701613</td>\n",
       "      <td>0.416728</td>\n",
       "      <td>0.357466</td>\n",
       "      <td>0.379014</td>\n",
       "      <td>0.762923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>microsoft/deberta-base</td>\n",
       "      <td>concreteness_score_addition</td>\n",
       "      <td>artificial_train_combined</td>\n",
       "      <td>4</td>\n",
       "      <td>0.685289</td>\n",
       "      <td>0.420415</td>\n",
       "      <td>0.403362</td>\n",
       "      <td>0.408644</td>\n",
       "      <td>0.751175</td>\n",
       "      <td>0.675558</td>\n",
       "      <td>0.395915</td>\n",
       "      <td>0.376080</td>\n",
       "      <td>0.382074</td>\n",
       "      <td>0.760869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>microsoft/deberta-base</td>\n",
       "      <td>concreteness_score_addition</td>\n",
       "      <td>artificial_train_combined</td>\n",
       "      <td>2</td>\n",
       "      <td>0.700186</td>\n",
       "      <td>0.431362</td>\n",
       "      <td>0.370173</td>\n",
       "      <td>0.390604</td>\n",
       "      <td>0.754458</td>\n",
       "      <td>0.702854</td>\n",
       "      <td>0.430742</td>\n",
       "      <td>0.372480</td>\n",
       "      <td>0.391670</td>\n",
       "      <td>0.757785</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               model_name                     strategy  \\\n",
       "6  microsoft/deberta-base  concreteness_score_addition   \n",
       "7  microsoft/deberta-base  concreteness_score_addition   \n",
       "5  microsoft/deberta-base  concreteness_score_addition   \n",
       "\n",
       "          train_dataset_type  epoch  validation_accuracy  \\\n",
       "6  artificial_train_combined      3             0.700807   \n",
       "7  artificial_train_combined      4             0.685289   \n",
       "5  artificial_train_combined      2             0.700186   \n",
       "\n",
       "   validation_precision  validation_recall  validation_f1  validation_roc_auc  \\\n",
       "6              0.433721           0.359241       0.383321            0.750411   \n",
       "7              0.420415           0.403362       0.408644            0.751175   \n",
       "5              0.431362           0.370173       0.390604            0.754458   \n",
       "\n",
       "   test_accuracy  test_precision  test_recall   test_f1  test_roc_auc  \n",
       "6       0.701613        0.416728     0.357466  0.379014      0.762923  \n",
       "7       0.675558        0.395915     0.376080  0.382074      0.760869  \n",
       "5       0.702854        0.430742     0.372480  0.391670      0.757785  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[results_df.train_dataset_type == \"artificial_train_combined\"].sort_values(by=['test_roc_auc'], ascending=False).head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf1eaa9-2228-4ca6-9ae2-c0242872e3a9",
   "metadata": {},
   "source": [
    "Here, we can see that BART is performing better with the concreteness score and artificial data, this is interesting because when we were doing individual model experiments, DeBERTa model was getting better results with the addition of concreteness score on 2 epochs of training, but we can't see that result here (it might be due to random state in intialization of the models). We are unable to recreate it with this code but you can check it out in the following notebook: /modelling/adept/experiments/FinalModellingWithConcretenessScoreSequence[DeBERTa] - ADEPT.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc4f9b6-dc3b-46f7-8c3d-ef6952e7572e",
   "metadata": {},
   "source": [
    "In one experiment, we were getting ROC-AUC of .785589, but due to randomness, we are not able to recreate it. Maybe we will experiment and try to get it before the presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e34bc89-efd7-418a-b964-89970ee7827c",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('../../results/FinalResultsADEPTNew.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad28385d-9a1a-44ec-8bae-8f3bdec13081",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
