{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3a28baba-703d-46b5-9083-d6a2a801d281",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c72ea1e8-bbb5-4805-989a-78c496dabc5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b6e8d3b-b1f0-4abc-8713-58fd5c880513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0328d790-8750-4766-bc92-ac62e300806f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  test.json  train.json  val.json\n"
     ]
    }
   ],
   "source": [
    "!ls ../datasets/adept/train-dev-test-split/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a157adb2-742a-43ac-96c9-f4df0624229a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d7e17f4-6b02-488a-a4c3-06084df5a592",
   "metadata": {},
   "outputs": [],
   "source": [
    "adept_data_path = \"../datasets/adept/train-dev-test-split\"\n",
    "split = \"train\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1565a805-ea81-4d99-93c2-44c9343c89c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = json.load(open('{}/{}.json'.format(adept_data_path, split), 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d89e5623-8fe8-4815-a11b-1f3368b732c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>modifier</th>\n",
       "      <th>noun</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The effect of sleeping is rejuvenation.</td>\n",
       "      <td>The effect of additional sleeping is rejuvenat...</td>\n",
       "      <td>additional</td>\n",
       "      <td>sleeping</td>\n",
       "      <td>3</td>\n",
       "      <td>13484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A toothbrush is for fresh breath.</td>\n",
       "      <td>A regular toothbrush is for fresh breath.</td>\n",
       "      <td>regular</td>\n",
       "      <td>toothbrush</td>\n",
       "      <td>2</td>\n",
       "      <td>2620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A scene is painted.</td>\n",
       "      <td>A negative scene is painted.</td>\n",
       "      <td>negative</td>\n",
       "      <td>scene</td>\n",
       "      <td>2</td>\n",
       "      <td>3324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A bone breaks a tooth.</td>\n",
       "      <td>An alleged bone breaks a tooth.</td>\n",
       "      <td>alleged</td>\n",
       "      <td>bone</td>\n",
       "      <td>2</td>\n",
       "      <td>10610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A trip causes a happening.</td>\n",
       "      <td>A fabulous trip causes a happening.</td>\n",
       "      <td>fabulous</td>\n",
       "      <td>trip</td>\n",
       "      <td>2</td>\n",
       "      <td>14917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sentence1  \\\n",
       "0  The effect of sleeping is rejuvenation.   \n",
       "1        A toothbrush is for fresh breath.   \n",
       "2                      A scene is painted.   \n",
       "3                   A bone breaks a tooth.   \n",
       "4               A trip causes a happening.   \n",
       "\n",
       "                                           sentence2    modifier        noun  \\\n",
       "0  The effect of additional sleeping is rejuvenat...  additional    sleeping   \n",
       "1          A regular toothbrush is for fresh breath.     regular  toothbrush   \n",
       "2                       A negative scene is painted.    negative       scene   \n",
       "3                    An alleged bone breaks a tooth.     alleged        bone   \n",
       "4                A fabulous trip causes a happening.    fabulous        trip   \n",
       "\n",
       "   label    idx  \n",
       "0      3  13484  \n",
       "1      2   2620  \n",
       "2      2   3324  \n",
       "3      2  10610  \n",
       "4      2  14917  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame(train_data)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95b9e6b3-0098-4a2d-bbb7-907d165742a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_class_map = {0:\"Impossible\", 1:\"Less Likely\", 2:\"Equally Likely\", 3:\"More Likely\", 4:\"Necessarily True\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a016b8fa-755f-4fab-981c-8032a1e24ed7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['Impossible', 'Less Likely', 'Equally Likely', 'More Likely', 'Necessarily True'])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_to_class_map.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15c55742-f396-457c-9aaa-b67a42a0011f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>modifier</th>\n",
       "      <th>noun</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "      <th>sentence2_preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The effect of sleeping is rejuvenation.</td>\n",
       "      <td>The effect of additional sleeping is rejuvenat...</td>\n",
       "      <td>additional</td>\n",
       "      <td>sleeping</td>\n",
       "      <td>3</td>\n",
       "      <td>13484</td>\n",
       "      <td>the effect of additional sleeping is rejuvenation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A toothbrush is for fresh breath.</td>\n",
       "      <td>A regular toothbrush is for fresh breath.</td>\n",
       "      <td>regular</td>\n",
       "      <td>toothbrush</td>\n",
       "      <td>2</td>\n",
       "      <td>2620</td>\n",
       "      <td>a regular toothbrush is for fresh breath</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sentence1  \\\n",
       "0  The effect of sleeping is rejuvenation.   \n",
       "1        A toothbrush is for fresh breath.   \n",
       "\n",
       "                                           sentence2    modifier        noun  \\\n",
       "0  The effect of additional sleeping is rejuvenat...  additional    sleeping   \n",
       "1          A regular toothbrush is for fresh breath.     regular  toothbrush   \n",
       "\n",
       "   label    idx                             sentence2_preprocessed  \n",
       "0      3  13484  the effect of additional sleeping is rejuvenation  \n",
       "1      2   2620           a regular toothbrush is for fresh breath  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['sentence2_preprocessed'] = df_train['sentence2'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "df_train['sentence2_preprocessed'] = df_train['sentence2_preprocessed'].map(lambda x: x.lower())\n",
    "# df_train['class_label'] = df_train.label.map(lambda x: label_to_class_map[x])\n",
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bb31ed6b-e734-40f1-ae04-3d644129d764",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Bigram</th>\n",
       "      <th>Conc.M</th>\n",
       "      <th>Conc.SD</th>\n",
       "      <th>Unknown</th>\n",
       "      <th>Total</th>\n",
       "      <th>Percent_known</th>\n",
       "      <th>SUBTLEX</th>\n",
       "      <th>Dom_Pos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>roadsweeper</td>\n",
       "      <td>0</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0.37</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>traindriver</td>\n",
       "      <td>0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.71</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word  Bigram  Conc.M  Conc.SD  Unknown  Total  Percent_known  \\\n",
       "0  roadsweeper       0    4.85     0.37        1     27           0.96   \n",
       "1  traindriver       0    4.54     0.71        3     29           0.90   \n",
       "\n",
       "   SUBTLEX Dom_Pos  \n",
       "0        0       0  \n",
       "1        0       0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We got this dataset for concreteness of 40k words (https://pubmed.ncbi.nlm.nih.gov/24142837/) from https://web.stanford.edu/class/linguist278/data/\n",
    "concreteness_df = pd.read_csv('../datasets/concreteness/Concreteness_ratings_Brysbaert_et_al_BRM.csv')\n",
    "concreteness_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "784bf63a-ea2e-49b7-b6fa-68222779677a",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_concreteness_score_map = dict()\n",
    "for idx, row in concreteness_df.iterrows():\n",
    "    row = row.to_dict()\n",
    "    word_to_concreteness_score_map[row['Word']] = row['Conc.M']/5.0 # Normalizing to a scale of 0 to 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb5eef04-632c-4bea-a8fd-ac1de97ad27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39954"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_concreteness_score_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6baf8c30-513d-4b9d-97cc-fb571a09e36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_concreteness_score(word):\n",
    "    \"\"\"\n",
    "    Get the concreteness score of a word based on the Concreteness Ratings dataset.\n",
    "    \"\"\"\n",
    "    # If the word is not found in the dataset, return a default score of 0.5\n",
    "    return word_to_concreteness_score_map.get(word, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "41a244c3-783f-4464-8aad-0998ec5a5c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_text_concreteness(text):\n",
    "    \"\"\"\n",
    "    Calculate the concreteness score for a given text.\n",
    "    \"\"\"\n",
    "    words = nltk.word_tokenize(text)\n",
    "    concreteness_scores = [get_concreteness_score(word) for word in words]\n",
    "    # Take the average concreteness score of all words in the text\n",
    "    return sum(concreteness_scores) / len(concreteness_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3cc9123-912a-47f4-8000-7af7e9e272e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concreteness Score: 0.5246666666666667\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "text = \"the laws of the world can't stop him\"\n",
    "concreteness_score = calculate_text_concreteness(text)\n",
    "print(f\"Concreteness Score: {concreteness_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0e242c3-0be5-4be5-934d-ce2adf258063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concreteness Score: 0.868\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "text = \"car crash\"\n",
    "concreteness_score = calculate_text_concreteness(text)\n",
    "print(f\"Concreteness Score: {concreteness_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92b98d4a-534f-4558-b9f0-b7525a3e0308",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['concreteness_score'] = df_train.sentence2_preprocessed.apply(calculate_text_concreteness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f8be043-4951-4da4-8325-5c977a806d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>modifier</th>\n",
       "      <th>noun</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "      <th>sentence2_preprocessed</th>\n",
       "      <th>concreteness_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The effect of sleeping is rejuvenation.</td>\n",
       "      <td>The effect of additional sleeping is rejuvenat...</td>\n",
       "      <td>additional</td>\n",
       "      <td>sleeping</td>\n",
       "      <td>3</td>\n",
       "      <td>13484</td>\n",
       "      <td>the effect of additional sleeping is rejuvenation</td>\n",
       "      <td>0.435714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A toothbrush is for fresh breath.</td>\n",
       "      <td>A regular toothbrush is for fresh breath.</td>\n",
       "      <td>regular</td>\n",
       "      <td>toothbrush</td>\n",
       "      <td>2</td>\n",
       "      <td>2620</td>\n",
       "      <td>a regular toothbrush is for fresh breath</td>\n",
       "      <td>0.526000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 sentence1  \\\n",
       "0  The effect of sleeping is rejuvenation.   \n",
       "1        A toothbrush is for fresh breath.   \n",
       "\n",
       "                                           sentence2    modifier        noun  \\\n",
       "0  The effect of additional sleeping is rejuvenat...  additional    sleeping   \n",
       "1          A regular toothbrush is for fresh breath.     regular  toothbrush   \n",
       "\n",
       "   label    idx                             sentence2_preprocessed  \\\n",
       "0      3  13484  the effect of additional sleeping is rejuvenation   \n",
       "1      2   2620           a regular toothbrush is for fresh breath   \n",
       "\n",
       "   concreteness_score  \n",
       "0            0.435714  \n",
       "1            0.526000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "14aeac54-5080-4c85-b8f2-14756ef15a46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12892, 8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff794fc4-c794-4cd9-b7b6-eb7b1315b77f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1611, 6) (1612, 6)\n"
     ]
    }
   ],
   "source": [
    "df_validation = pd.DataFrame(json.load(open('{}/{}.json'.format(adept_data_path, \"val\"), 'r')))\n",
    "df_test = pd.DataFrame(json.load(open('{}/{}.json'.format(adept_data_path, \"test\"), 'r')))\n",
    "print(df_validation.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b3031a8d-a585-4f9f-b433-45e384b3006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation['sentence2_preprocessed'] = df_validation['sentence2'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "df_validation['sentence2_preprocessed'] = df_validation['sentence2_preprocessed'].map(lambda x: x.lower())\n",
    "df_validation['concreteness_score'] = df_validation.sentence2_preprocessed.apply(calculate_text_concreteness)\n",
    "\n",
    "df_test['sentence2_preprocessed'] = df_test['sentence2'].map(lambda x: re.sub('[,\\.!?]', '', x))\n",
    "df_test['sentence2_preprocessed'] = df_test['sentence2_preprocessed'].map(lambda x: x.lower())\n",
    "df_test['concreteness_score'] = df_test.sentence2_preprocessed.apply(calculate_text_concreteness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aff13f1-7ab5-4685-95c5-81dc1d261d34",
   "metadata": {},
   "source": [
    "# Fine Tuning Bert Base Uncased on ADEPT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314eb2d5-7462-4b73-9331-8f4287391d6e",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fafe14d4-5175-4bc0-8e2b-9f1f77956e68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel\n",
    "from transformers import DataCollatorWithPadding, get_scheduler\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fcb482a7-b289-4fce-9ef5-b9b85f07ace7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../datasets/adept/train-dev-test-split'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adept_data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e66ff214-5ef6-4af0-8ca4-9ca96b65827c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md  test.json  train.json  val.json\n"
     ]
    }
   ],
   "source": [
    "!ls '../datasets/adept/train-dev-test-split'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54644933-cc35-4306-8224-09db821ad0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = \"train.json\"\n",
    "validation_split = \"val.json\"\n",
    "test_split = \"test.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6a645e70-ca3e-4d9e-b0ac-ab2aaaedd309",
   "metadata": {},
   "outputs": [],
   "source": [
    "adept_dataset = DatasetDict({\n",
    "    'train': Dataset.from_pandas(df_train),\n",
    "    'validation': Dataset.from_pandas(df_validation),\n",
    "    'test': Dataset.from_pandas(df_test)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "17a5cad0-543e-4a48-a534-e03ead568db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'modifier', 'noun', 'label', 'idx', 'sentence2_preprocessed', 'concreteness_score'],\n",
       "        num_rows: 12892\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'modifier', 'noun', 'label', 'idx', 'sentence2_preprocessed', 'concreteness_score'],\n",
       "        num_rows: 1611\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence1', 'sentence2', 'modifier', 'noun', 'label', 'idx', 'sentence2_preprocessed', 'concreteness_score'],\n",
       "        num_rows: 1612\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adept_dataset = load_dataset(\"json\", data_files=data_files)\n",
    "adept_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "af5ce803-b5d5-4f7e-b686-ba2d5562b27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value(dtype='string', id=None),\n",
       " 'sentence2': Value(dtype='string', id=None),\n",
       " 'modifier': Value(dtype='string', id=None),\n",
       " 'noun': Value(dtype='string', id=None),\n",
       " 'label': Value(dtype='int64', id=None),\n",
       " 'idx': Value(dtype='int64', id=None),\n",
       " 'sentence2_preprocessed': Value(dtype='string', id=None),\n",
       " 'concreteness_score': Value(dtype='float64', id=None)}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adept_dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37de10af-b6c2-4e5b-a42a-d55e530958b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': 'A year is made up of 365 days.',\n",
       " 'sentence2': 'An outstanding year is made up of 365 days.',\n",
       " 'modifier': 'outstanding',\n",
       " 'noun': 'year',\n",
       " 'label': 2,\n",
       " 'idx': 2825,\n",
       " 'sentence2_preprocessed': 'an outstanding year is made up of 365 days',\n",
       " 'concreteness_score': 0.48733333333333334}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adept_dataset['train'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d449483-b077-4b64-8f62-c26628d21b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'learning_rate': 3.660515504756857e-05,\n",
    " 'num_train_epochs': 3,\n",
    " 'model_name': 'microsoft/deberta-base'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dd856392-129b-4ed3-8968-1581bb729f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = best_params['model_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ce1656e9-ab9a-4305-bf68-db3406ee507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dict = {\"BERT\": \"bert-base-uncased\",\n",
    "\"ROBERTA\": \"grammarly/detexd-roberta-base\",\n",
    "\"DEBERTA\": \"sileod/deberta-v3-base-tasksource-nli\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1aa03946-023e-4730-99d7-7825b47b5530",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8e6da47-3730-4107-ac17-77bef814247b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=5, ignore_mismatched_sizes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c0dc8f47-070a-48fc-acbf-73beb908aa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_sentence(item):\n",
    "    return tokenizer(item['sentence2'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5b323805-73bb-4b8b-803d-39d705173a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 12892/12892 [00:00<00:00, 43526.39 examples/s]\n",
      "Map: 100%|██████████| 1611/1611 [00:00<00:00, 67098.53 examples/s]\n",
      "Map: 100%|██████████| 1612/1612 [00:00<00:00, 54113.12 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = adept_dataset.map(tokenize_sentence, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849824e8-92c4-46f7-b3b8-6004bf52c321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7cbf8cfd-6c8a-4858-98a3-e61276cdb2a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence1': Value(dtype='string', id=None),\n",
       " 'sentence2': Value(dtype='string', id=None),\n",
       " 'modifier': Value(dtype='string', id=None),\n",
       " 'noun': Value(dtype='string', id=None),\n",
       " 'label': Value(dtype='int64', id=None),\n",
       " 'idx': Value(dtype='int64', id=None),\n",
       " 'sentence2_preprocessed': Value(dtype='string', id=None),\n",
       " 'concreteness_score': Value(dtype='float64', id=None),\n",
       " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
       " 'token_type_ids': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
       " 'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['train'].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "33bb7d11-a4f5-47e6-b915-87ec886cded3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'concreteness_score', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 12892\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['labels', 'concreteness_score', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1611\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'concreteness_score', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 1612\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = tokenized_dataset.remove_columns(['sentence1', 'sentence2', 'idx', 'modifier', 'noun', 'sentence2_preprocessed'])\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "tokenized_dataset = tokenized_dataset.with_format(\"torch\")\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dee6bd96-ad41-45c6-bd74-89b0d963889d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97ee052f-fa87-47c3-9a8d-cd88b128f9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# headless_model = AutoModel.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "80b160cd-a502-4d10-b4b4-72a334dbfe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# headless_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5782f29f-e60b-43b1-a19b-190b34b023cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7bfd3515-d38e-4788-9a56-f7655380cbb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "73c47abe-2b6e-4191-848e-7cbb6d1c0b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = AutoConfig.from_pretrained(checkpoint, num_labels=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d8d26a4-d3ee-4d32-bb15-22d3c1776f67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22f7aec8-7a35-4c5f-856a-284b72d9ba61",
   "metadata": {},
   "source": [
    "#### Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1059e6a7-4a14-4a30-a39e-2294433de6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0e784af5-fcbe-475f-87ad-7cde0f5bbe2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "transformers.models.deberta.modeling_deberta.ContextPooler"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformers.models.deberta.modeling_deberta.ContextPooler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c54ae4f8-45a0-457a-a7c5-cf07d92b27bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomModel, self).__init__()\n",
    "        self.deberta = AutoModel.from_pretrained('distilbert-base-uncased')\n",
    "        self.linear = torch.nn.Linear(in_features=768 + 1, out_features=2)  # Adjust input size\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, feature):\n",
    "        bert_output = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
    "        combined_input = torch.cat((bert_output, feature), dim=1)\n",
    "        output = self.linear(combined_input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15a6eda5-9b12-4292-993e-6232fa12ce7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.models.deberta.modeling_deberta import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4818235a-b193-4558-81f7-915b23388d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDebertaForSequenceClassification(DebertaPreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "\n",
    "        num_labels = getattr(config, \"num_labels\", 2)\n",
    "        self.num_labels = num_labels\n",
    "\n",
    "        self.deberta = DebertaModel(config)\n",
    "        self.pooler = ContextPooler(config)\n",
    "        output_dim = self.pooler.output_dim\n",
    "\n",
    "        ###### +1 for concreteness score ######\n",
    "        self.classifier = torch.nn.Linear(in_features=output_dim+1, out_features=num_labels) \n",
    "        drop_out = getattr(config, \"cls_dropout\", None)\n",
    "        drop_out = self.config.hidden_dropout_prob if drop_out is None else drop_out\n",
    "        self.dropout = StableDropout(drop_out)\n",
    "\n",
    "        # Initialize weights and apply final processing\n",
    "        self.post_init()\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        concreteness_score: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, SequenceClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.deberta(\n",
    "            input_ids,\n",
    "            token_type_ids=token_type_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            position_ids=position_ids,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        encoder_layer = outputs[0]\n",
    "        pooled_output = self.pooler(encoder_layer)\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        ##### combining concreteness score input with pooled context #####\n",
    "        ##### Unsqueezing concreteness score to match dimensions #####\n",
    "        combined_input = torch.cat((pooled_output, concreteness_score.unsqueeze(1)), dim=1)\n",
    "        logits = self.classifier(combined_input)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    # regression task\n",
    "                    loss_fn = nn.MSELoss()\n",
    "                    logits = logits.view(-1).to(labels.dtype)\n",
    "                    loss = loss_fn(logits, labels.view(-1))\n",
    "                elif labels.dim() == 1 or labels.size(-1) == 1:\n",
    "                    label_index = (labels >= 0).nonzero()\n",
    "                    labels = labels.long()\n",
    "                    if label_index.size(0) > 0:\n",
    "                        labeled_logits = torch.gather(\n",
    "                            logits, 0, label_index.expand(label_index.size(0), logits.size(1))\n",
    "                        )\n",
    "                        labels = torch.gather(labels, 0, label_index.view(-1))\n",
    "                        loss_fct = CrossEntropyLoss()\n",
    "                        loss = loss_fct(labeled_logits.view(-1, self.num_labels).float(), labels.view(-1))\n",
    "                    else:\n",
    "                        loss = torch.tensor(0).to(logits)\n",
    "                else:\n",
    "                    log_softmax = nn.LogSoftmax(-1)\n",
    "                    loss = -((log_softmax(logits) * labels).sum(-1)).mean()\n",
    "            elif self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e70bb538-68b1-4d0b-b9b7-818152798df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_model = CustomDebertaForSequenceClassification(model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8d3f970b-351a-4913-a199-cd76923dcf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomDebertaForSequenceClassification(\n",
       "  (deberta): DebertaModel(\n",
       "    (embeddings): DebertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
       "      (LayerNorm): DebertaLayerNorm()\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(1024, 768)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=769, out_features=5, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "300408ca-d8a1-4edf-9e7a-401f42da1755",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# # Step 5: Adjust Training Loop\n",
    "# model = CustomModel()\n",
    "# criterion = torch.nn.CrossEntropyLoss()\n",
    "# optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ffb03a-ea8b-49a9-9cd4-cdfc9d8755f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "da9d9fb9-8f29-48c9-89c2-bfe2865f7fd2",
   "metadata": {},
   "source": [
    "#### Setting Up Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "59b0942a-4bcc-4d3a-93dd-1aa868c68168",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 1\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ba5f072d-2d8f-4b0f-8bdc-81d44e5cdb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "856f1c4c-2d22-42b8-b4e8-9752c5546211",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "47e6be41-cbd6-4568-a106-caaafae0ffc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_dataset['train'], batch_size=batch_size, shuffle=True, collate_fn=data_collator)\n",
    "validation_dataloader = DataLoader(tokenized_dataset['validation'], batch_size=batch_size, collate_fn=data_collator)\n",
    "test_dataloader = DataLoader(tokenized_dataset['test'], batch_size=batch_size, collate_fn=data_collator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c405044f-3e5c-444b-9bb5-5b7dbb788608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available else torch.device(\"cpu\")\n",
    "custom_model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d587af8-718f-4033-83fb-69dbfede5b19",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9802ba-3696-43d1-8e5e-2585aff7e81c",
   "metadata": {},
   "source": [
    "#### Setting up Optimizer with deacaying learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "058ecafe-5f09-4899-b7ab-1298bd630b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.adamw import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "748f2537-8eb6-42f7-a636-a34063411ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(custom_model.parameters(), lr=3.660515504756857e-05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "33c08a13-b156-4e82-b03e-8ecb70dd3c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_training_steps = num_epochs*len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "97f70e8b-53ff-4073-aa3d-19596560eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47a69143-07d5-4576-8265-3506a871dbbb",
   "metadata": {},
   "source": [
    "#### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e25ef78a-4180-4657-9a7e-f4b7651df897",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1209 [00:00<?, ?it/s]You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 1209/1209 [07:36<00:00,  3.67it/s]"
     ]
    }
   ],
   "source": [
    "progress_bar = tqdm(range(num_training_steps))\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        batch = {k:v.to(device) for k, v in batch.items()}\n",
    "        outputs = custom_model(**batch)\n",
    "        loss = outputs.loss\n",
    "        # calculating gradients\n",
    "        loss.backward()\n",
    "        # optimizing weights\n",
    "        optimizer.step()\n",
    "        # updating learning rate\n",
    "        learning_rate_scheduler.step()\n",
    "        # flushing gradients\n",
    "        optimizer.zero_grad()\n",
    "        # updating progress bar\n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716a7fe1-23f8-4540-af57-fb85ad0de117",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "e6013a6e-08dc-4095-b808-a36392922b94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomDebertaForSequenceClassification(\n",
       "  (deberta): DebertaModel(\n",
       "    (embeddings): DebertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=0)\n",
       "      (LayerNorm): DebertaLayerNorm()\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x DebertaLayer(\n",
       "          (attention): DebertaAttention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (in_proj): Linear(in_features=768, out_features=2304, bias=False)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (pos_proj): Linear(in_features=768, out_features=768, bias=False)\n",
       "              (pos_q_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): DebertaLayerNorm()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): DebertaLayerNorm()\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(1024, 768)\n",
       "    )\n",
       "  )\n",
       "  (pooler): ContextPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): StableDropout()\n",
       "  )\n",
       "  (classifier): Linear(in_features=769, out_features=5, bias=True)\n",
       "  (dropout): StableDropout()\n",
       ")"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "custom_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "41d606f2-8d07-424e-8764-fa8c7afafd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9f134f08-4869-4847-98c4-0f3d0146c6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = evaluate.load('accuracy')\n",
    "precision = evaluate.load('precision')\n",
    "recall = evaluate.load('recall')\n",
    "f1 = evaluate.load('f1')\n",
    "roc_auc =  evaluate.load(\"roc_auc\", \"multiclass\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "57a2fa04-d1b9-4bc1-952f-2b4e744e07fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [accuracy, precision, recall, f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6c700b-799e-4918-b970-b4ab1f9c0272",
   "metadata": {},
   "source": [
    "#### Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e9867d79-9c56-4c32-a632-6741752d780b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8dd67a1a-3737-40e5-893f-95ca31d6d33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "03337545-99a6-4665-9c29-9e650ba3db2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for batch in validation_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = custom_model(**batch)\n",
    "    # Extract logits and predictions\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    # Apply softmax to convert logits to probabilities\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    \n",
    "    # Extract probabilities for the positive class\n",
    "    positive_probabilities = probabilities\n",
    "\n",
    "    # Update metrics for accuracy, precision, recall, and F1\n",
    "    for metric in metrics:\n",
    "        metric.add_batch(predictions=predictions, references=batch['labels'])\n",
    "\n",
    "    # Update ROC AUC metric\n",
    "    roc_auc.add_batch(prediction_scores=positive_probabilities, references=batch['labels'])\n",
    "\n",
    "# # Compute metrics for accuracy, precision, recall, and F1\n",
    "validation_eval_dict = {}\n",
    "# for metric in metrics.values():\n",
    "#     eval_dict.update(metric.compute(average=\"macro\"))\n",
    "\n",
    "validation_eval_dict.update(accuracy.compute())\n",
    "validation_eval_dict.update(precision.compute(average=\"macro\"))\n",
    "validation_eval_dict.update(recall.compute(average=\"macro\"))\n",
    "validation_eval_dict.update(f1.compute(average=\"macro\"))\n",
    "validation_eval_dict.update(roc_auc.compute(multi_class='ovo', average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "42bab3f6-dde1-4884-9065-9e4571bf5c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.65983860955928,\n",
       " 'precision': 0.28776653062324054,\n",
       " 'recall': 0.27802638010999664,\n",
       " 'f1': 0.2769530906793819,\n",
       " 'roc_auc': 0.6346530029171855}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_valid_3_res = {'accuracy': 0.65983860955928,\n",
    " 'precision': 0.28776653062324054,\n",
    " 'recall': 0.27802638010999664,\n",
    " 'f1': 0.2769530906793819,\n",
    " 'roc_auc': 0.6346530029171855}\n",
    "prev_valid_3_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "daa660f3-3bd9-4edb-b9b7-9a6135dddf6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5859714463066419,\n",
       " 'precision': 0.2790926099980391,\n",
       " 'recall': 0.27399491306003604,\n",
       " 'f1': 0.2757435501839343,\n",
       " 'roc_auc': 0.5916102736812134}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_valid_10_res = {'accuracy': 0.5859714463066419,\n",
    " 'precision': 0.2790926099980391,\n",
    " 'recall': 0.27399491306003604,\n",
    " 'f1': 0.2757435501839343,\n",
    " 'roc_auc': 0.5916102736812134}\n",
    "prev_valid_10_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "90acec77-17e8-4495-825d-5773ab2af375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.65983860955928,\n",
       " 'precision': 0.28776653062324054,\n",
       " 'recall': 0.27802638010999664,\n",
       " 'f1': 0.2769530906793819,\n",
       " 'roc_auc': 0.6346530029171855}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1f089824-0bc6-4d72-9167-cf0e5e4ea750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for batch in test_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = custom_model(**batch)\n",
    "    # Extract logits and predictions\n",
    "    logits = outputs.logits\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "\n",
    "    # Apply softmax to convert logits to probabilities\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    \n",
    "    # Extract probabilities for the positive class\n",
    "    positive_probabilities = probabilities\n",
    "\n",
    "    # Update metrics for accuracy, precision, recall, and F1\n",
    "    for metric in metrics:\n",
    "        metric.add_batch(predictions=predictions, references=batch['labels'])\n",
    "\n",
    "    # Update ROC AUC metric\n",
    "    roc_auc.add_batch(prediction_scores=positive_probabilities, references=batch['labels'])\n",
    "\n",
    "# # Compute metrics for accuracy, precision, recall, and F1\n",
    "test_eval_dict = {}\n",
    "# for metric in metrics.values():\n",
    "#     eval_dict.update(metric.compute(average=\"macro\"))\n",
    "\n",
    "test_eval_dict.update(accuracy.compute())\n",
    "test_eval_dict.update(precision.compute(average=\"macro\"))\n",
    "test_eval_dict.update(recall.compute(average=\"macro\"))\n",
    "test_eval_dict.update(f1.compute(average=\"macro\"))\n",
    "test_eval_dict.update(roc_auc.compute(multi_class='ovo', average=\"macro\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8fbf12a5-895a-48e5-bcb9-7c638c59fecc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.673697270471464,\n",
       " 'precision': 0.2849209452293981,\n",
       " 'recall': 0.2732542150719794,\n",
       " 'f1': 0.27303419884506624,\n",
       " 'roc_auc': 0.6543617977047307}"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_test_3_res = {'accuracy': 0.673697270471464,\n",
    " 'precision': 0.2849209452293981,\n",
    " 'recall': 0.2732542150719794,\n",
    " 'f1': 0.27303419884506624,\n",
    " 'roc_auc': 0.6543617977047307}\n",
    "prev_test_3_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a3a21537-ba57-43e1-b9d0-7b083b7bb37a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.5859714463066419,\n",
       " 'precision': 0.2790926099980391,\n",
       " 'recall': 0.27399491306003604,\n",
       " 'f1': 0.2757435501839343,\n",
       " 'roc_auc': 0.5916102736812134}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prev_test_10_res = {'accuracy': 0.5859714463066419,\n",
    " 'precision': 0.2790926099980391,\n",
    " 'recall': 0.27399491306003604,\n",
    " 'f1': 0.2757435501839343,\n",
    " 'roc_auc': 0.5916102736812134}\n",
    "prev_test_10_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dc35822c-0528-4667-be6f-5f09bbf41076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.673697270471464,\n",
       " 'precision': 0.2849209452293981,\n",
       " 'recall': 0.2732542150719794,\n",
       " 'f1': 0.27303419884506624,\n",
       " 'roc_auc': 0.6543617977047307}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_eval_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197119e8-ab64-4c5f-946c-726da001cb54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bd6b43-70a7-416e-b309-cdf9da7b8007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
