{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PAP (Binary) - Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saponaro/Developer/uni/noble-owl/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import nltk\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, AutoModel\n",
    "from transformers import DataCollatorWithPadding, get_scheduler\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from tqdm.auto import tqdm\n",
    "import evaluate\n",
    "\n",
    "# Loads PAP datasets\n",
    "datasets_path = '../datasets/pap/train-dev-test-split/binary'\n",
    "train_df = pd.read_csv(f'{datasets_path}/train.csv')\n",
    "dev_df = pd.read_csv(f'{datasets_path}/dev.csv')\n",
    "test_df = pd.read_csv(f'{datasets_path}/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loads and preprocess concreteness ratings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We got this dataset for concreteness of 40k words (https://pubmed.ncbi.nlm.nih.gov/24142837/) from https://web.stanford.edu/class/linguist278/data/\n",
    "# Load concreteness ratings\n",
    "concreteness_df = pd.read_csv('../datasets/concreteness/Concreteness_ratings_Brysbaert_et_al_BRM.csv')\n",
    "concreteness_df.head(2)\n",
    "\n",
    "# Map and normalize conreteness ratings\n",
    "word_to_concreteness_score_map = dict()\n",
    "for idx, row in concreteness_df.iterrows():\n",
    "    row = row.to_dict()\n",
    "    \n",
    "    # Normalizing to a scale of 0 to 1\n",
    "    word_to_concreteness_score_map[row['Word']] = row['Conc.M']/5.0 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define helper functions to get concreteness scores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_concreteness_score(word):\n",
    "    \"\"\"\n",
    "    Get the concreteness score of a word based on the Concreteness Ratings dataset.\n",
    "    \"\"\"\n",
    "    # If the word is not found in the dataset, return a default score of 0.5\n",
    "    return round(word_to_concreteness_score_map.get(word, 0.5), 3)\n",
    "\n",
    "def calculate_text_concreteness_sequence(text):\n",
    "    \"\"\"\n",
    "    Calculate the concreteness score for a given text.\n",
    "    \"\"\"\n",
    "    words = nltk.word_tokenize(text)\n",
    "    concreteness_scores = [get_concreteness_score(word) for word in words]\n",
    "    concreteness_scores = \" \".join([str(i) for i in concreteness_scores])\n",
    "    # Take the average concreteness score of all words in the text\n",
    "    return concreteness_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load PAP datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add concreteness scores for the every sequence\n",
    "train_df['concreteness_score_sequence'] = train_df.text.apply(calculate_text_concreteness_sequence)\n",
    "dev_df['concreteness_score_sequence'] = dev_df.text.apply(calculate_text_concreteness_sequence)\n",
    "test_df['concreteness_score_sequence'] = test_df.text.apply(calculate_text_concreteness_sequence)\n",
    "\n",
    "# Load PAP datasets with Concreteness Scores  \n",
    "raw_datasets = DatasetDict({\n",
    "    'train': Dataset.from_pandas(train_df),\n",
    "    'validation': Dataset.from_pandas(dev_df),\n",
    "    'test': Dataset.from_pandas(test_df)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS_TO_KEEP = ['label', 'input_ids', 'token_type_ids', 'attention_mask']\n",
    "\n",
    "class ModellingExperiments:\n",
    "    \n",
    "    def __init__(self, model_name, dataset, batch_size, learning_rate):\n",
    "        self.model_name = model_name\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.learning_rate = learning_rate\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2, ignore_mismatched_sizes=True)\n",
    "        self.cols_to_keep = set(COLUMNS_TO_KEEP)\n",
    "        self.device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        self.data_collator = DataCollatorWithPadding(self.tokenizer)\n",
    "        self.model.to(self.device)\n",
    "        \n",
    "    def tokenize_sentence_with_concreteness_score(self, item):\n",
    "        # We also tried using the concreteness score for the whole sentence as a feature input\n",
    "        # To implement that, we changed the source code of transformers library and changed the classification head manually \n",
    "        # So that we can accomodate that extra feature, but this method of encoding concreteness score sequence was giving better score\n",
    "        # Hence, we are using this only in the final experiments. You can check that experiment out in the following notebook:\n",
    "        # modelling/pap/experiments/FinalModellingWithConcretenessScore[BERT] - PAP\n",
    "        return self.tokenizer(item['text'], item['concreteness_score_sequence'], truncation=True)\n",
    "        \n",
    "    def tokenize_sentence(self, item):\n",
    "        # Normal tokenization\n",
    "        return self.tokenizer(item['text'], truncation=True)\n",
    "        \n",
    "    def add_strategy_to_tokenizer_function_map(self):\n",
    "        # Mapping between strategy and the tokenization functions defined above\n",
    "        # Strategy refers to whether we are using normal tokenization or whether we want to do paired tokenization of \n",
    "        # both input sentence and the sequence of concreteness score for that sentence\n",
    "        self.strategy_to_tokenizer_function_map = dict()\n",
    "        self.strategy_to_tokenizer_function_map['normal_finetuning'] = self.tokenize_sentence_with_concreteness_score\n",
    "        self.strategy_to_tokenizer_function_map['concreteness_score_addition'] = self.tokenize_sentence\n",
    "        \n",
    "    def prepare_dataset(self, strategy):\n",
    "        # Here, we wull tokenize the dataset based on the strategy we are planning to use\n",
    "        self.strategy = strategy\n",
    "        self.add_strategy_to_tokenizer_function_map()\n",
    "        self.tokenized_dataset = self.dataset.map(self.strategy_to_tokenizer_function_map[self.strategy], batched=True)\n",
    "        current_cols = set(list(self.tokenized_dataset['train'].features.keys()))\n",
    "        self.tokenized_dataset = self.tokenized_dataset.remove_columns(list(current_cols - self.cols_to_keep))\n",
    "        self.tokenized_dataset = self.tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "        self.tokenized_dataset = self.tokenized_dataset.with_format(\"torch\")\n",
    "\n",
    "    def prepare_dataloaders(self):\n",
    "        self.train_dataloader = DataLoader(self.tokenized_dataset['train'], batch_size=self.batch_size, shuffle=True, collate_fn=self.data_collator)\n",
    "        self.validation_dataloader = DataLoader(self.tokenized_dataset['validation'], batch_size=self.batch_size, collate_fn=self.data_collator)\n",
    "        self.test_dataloader = DataLoader(self.tokenized_dataset['test'], batch_size=self.batch_size, collate_fn=self.data_collator)\n",
    "\n",
    "    def setup_optimizer(self, num_epochs):\n",
    "        # Setting up optimizer and learning rate scheduler\n",
    "        self.num_epochs = num_epochs\n",
    "        self.optimizer = AdamW(self.model.parameters(), lr=self.learning_rate)\n",
    "        self.num_training_steps = self.num_epochs*len(self.train_dataloader)\n",
    "        self.learning_rate_scheduler = get_scheduler(\"linear\", optimizer=self.optimizer, num_warmup_steps=0, num_training_steps=self.num_training_steps)\n",
    "    \n",
    "    def train_model(self):\n",
    "        # Training the Model\n",
    "        self.model.train()\n",
    "        progress_bar = tqdm(range(self.num_training_steps))\n",
    "        for epoch in range(self.num_epochs):\n",
    "            for batch in self.train_dataloader:\n",
    "                batch = {k:v.to(self.device) for k, v in batch.items()}\n",
    "                outputs = self.model(**batch)\n",
    "                loss = outputs.loss\n",
    "                # calculating gradients\n",
    "                loss.backward()\n",
    "                # optimizing weights\n",
    "                self.optimizer.step()\n",
    "                # updating learning rate\n",
    "                self.learning_rate_scheduler.step()\n",
    "                # flushing gradients\n",
    "                self.optimizer.zero_grad()\n",
    "                # updating progress bar\n",
    "                progress_bar.update(1)\n",
    "\n",
    "    def initialize_metrics(self):\n",
    "        self.metrics = {\n",
    "            'accuracy': evaluate.load('accuracy'),\n",
    "            'precision': evaluate.load('precision'),\n",
    "            'recall': evaluate.load('recall'),\n",
    "            'f1': evaluate.load('f1'),\n",
    "            'roc-auc': evaluate.load(\"roc_auc\"),\n",
    "        }\n",
    "                \n",
    "    def eval_model(self, dataloader):\n",
    "        # Run on GPU available\n",
    "        #device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "        \n",
    "        # Evaluating the model on different dataloaders\n",
    "        self.initialize_metrics()\n",
    "        \n",
    "        self.model.eval()\n",
    "        \n",
    "        for batch in dataloader:\n",
    "            # Move batch data to the specified device (GPU or CPU)\n",
    "            batch = {k: v.to(self.device) for k, v in batch.items()}\n",
    "    \n",
    "            # Forward pass\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model(**batch)\n",
    "            \n",
    "            # Extract logits and predictions\n",
    "            logits = outputs.logits\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "        \n",
    "            # Apply softmax to convert logits to probabilities\n",
    "            probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "            \n",
    "            # Extract probabilities for the positive class\n",
    "            positive_probabilities = probabilities[:, 1].to(self.device).numpy()\n",
    "        \n",
    "            # Update metrics for accuracy, precision, recall, F1 and ROC-AUC\n",
    "            self.metrics['accuracy'].add_batch(predictions=predictions, references=batch['labels'])\n",
    "            self.metrics['precision'].add_batch(predictions=predictions, references=batch['labels'])\n",
    "            self.metrics['recall'].add_batch(predictions=predictions, references=batch['labels'])\n",
    "            self.metrics['f1'].add_batch(predictions=predictions, references=batch['labels'])\n",
    "            self.metrics['roc-auc'].add_batch(prediction_scores=positive_probabilities, references=batch['labels'])\n",
    "        \n",
    "        # Compute metrics for accuracy, precision, recall, F1 and ROC-AUC\n",
    "        self.eval_dict = {}\n",
    "        self.eval_dict.update(self.metrics['accuracy'].compute())\n",
    "        self.eval_dict.update(self.metrics['precision'].compute(average=\"macro\"))\n",
    "        self.eval_dict.update(self.metrics['recall'].compute(average=\"macro\"))\n",
    "        self.eval_dict.update(self.metrics['f1'].compute(average=\"macro\"))\n",
    "        self.eval_dict.update(self.metrics['roc-auc'].compute(average=\"macro\"))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining parameters on which we will run the experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model parameters\n",
    "model_name_list = [\"facebook/bart-base\", \"microsoft/deberta-base\"]\n",
    "num_epochs_list = [1, 2, 3, 4, 5]\n",
    "strategies_list = [\"normal_finetuning\", \"concreteness_score_addition\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining static arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "kw_args = {\n",
    "    'dataset': raw_datasets,\n",
    "    'batch_size': 32,\n",
    "    'learning_rate': 3e-5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiments loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BartForSequenceClassification were not initialized from the model checkpoint at facebook/bart-base and are newly initialized: ['classification_head.out_proj.bias', 'classification_head.dense.bias', 'classification_head.dense.weight', 'classification_head.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1728/1728 [00:00<00:00, 62064.41 examples/s]\n",
      "Map: 100%|██████████| 216/216 [00:00<00:00, 37908.27 examples/s]\n",
      "Map: 100%|██████████| 216/216 [00:00<00:00, 42138.12 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training with the following Configurations: {'model_name': 'facebook/bart-base', 'strategy': 'normal_finetuning', 'num_epochs': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/54 [00:00<?, ?it/s]You're using a BartTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 54/54 [01:01<00:00,  1.14s/it]\n",
      "/Users/saponaro/Developer/uni/noble-owl/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.7129629629629629, 'precision': 0.35648148148148145, 'recall': 0.5, 'f1': 0.41621621621621624, 'roc_auc': 0.5528906577293674}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saponaro/Developer/uni/noble-owl/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Results: {'accuracy': 0.7129629629629629, 'precision': 0.35648148148148145, 'recall': 0.5, 'f1': 0.41621621621621624, 'roc_auc': 0.5438835358190197}\n",
      "Model Training with the following Configurations: {'model_name': 'facebook/bart-base', 'strategy': 'normal_finetuning', 'num_epochs': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [02:03<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.7546296296296297, 'precision': 0.716931216931217, 'recall': 0.6159405111018015, 'f1': 0.6249877157925771, 'roc_auc': 0.7924172601591956}\n",
      "Test Set Results: {'accuracy': 0.6851851851851852, 'precision': 0.5554655870445344, 'recall': 0.5286971093422707, 'f1': 0.514799154334038, 'roc_auc': 0.7250733137829912}\n",
      "Model Training with the following Configurations: {'model_name': 'facebook/bart-base', 'strategy': 'normal_finetuning', 'num_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [03:06<00:00,  1.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.7407407407407407, 'precision': 0.6838905775075987, 'recall': 0.6013824884792627, 'f1': 0.6070175438596491, 'roc_auc': 0.768537913699204}\n",
      "Test Set Results: {'accuracy': 0.7314814814814815, 'precision': 0.6623655913978495, 'recall': 0.5948889819857561, 'f1': 0.5994884910485934, 'roc_auc': 0.7400502723083369}\n",
      "Model Training with the following Configurations: {'model_name': 'facebook/bart-base', 'strategy': 'normal_finetuning', 'num_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [04:27<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.6712962962962963, 'precision': 0.5551109768986864, 'recall': 0.538227901131127, 'f1': 0.5348075348075348, 'roc_auc': 0.702869710934227}\n",
      "Test Set Results: {'accuracy': 0.7546296296296297, 'precision': 0.7018722633247773, 'recall': 0.6400293255131965, 'f1': 0.6527436527436528, 'roc_auc': 0.7422496857980728}\n",
      "Model Training with the following Configurations: {'model_name': 'facebook/bart-base', 'strategy': 'normal_finetuning', 'num_epochs': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 270/270 [05:42<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.6805555555555556, 'precision': 0.5532915360501567, 'recall': 0.5302681189777964, 'f1': 0.5197061003512616, 'roc_auc': 0.6816087138667783}\n",
      "Test Set Results: {'accuracy': 0.7083333333333334, 'precision': 0.6221208170360712, 'recall': 0.5882907415165479, 'f1': 0.5929526487391941, 'roc_auc': 0.7135525764558022}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<bound method ModellingExperiments.tokenize_sentence of <__main__.ModellingExperiments object at 0x29db68a10>> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Map: 100%|██████████| 1728/1728 [00:00<00:00, 93412.18 examples/s]\n",
      "Map: 100%|██████████| 216/216 [00:00<00:00, 62069.72 examples/s]\n",
      "Map: 100%|██████████| 216/216 [00:00<00:00, 62018.73 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training with the following Configurations: {'model_name': 'facebook/bart-base', 'strategy': 'concreteness_score_addition', 'num_epochs': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:42<00:00,  1.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.6990740740740741, 'precision': 0.5988574267262792, 'recall': 0.5625261834939255, 'f1': 0.5614555677026394, 'roc_auc': 0.6852744030163385}\n",
      "Test Set Results: {'accuracy': 0.7407407407407407, 'precision': 0.6771141336487285, 'recall': 0.6254713028906578, 'f1': 0.6356626506024097, 'roc_auc': 0.7166945957268538}\n",
      "Model Training with the following Configurations: {'model_name': 'facebook/bart-base', 'strategy': 'concreteness_score_addition', 'num_epochs': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [01:25<00:00,  1.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.6990740740740741, 'precision': 0.5960767218831735, 'recall': 0.5577084206116464, 'f1': 0.5546674279189266, 'roc_auc': 0.6726539589442815}\n",
      "Test Set Results: {'accuracy': 0.7222222222222222, 'precision': 0.6451803666469544, 'recall': 0.6028487641390867, 'f1': 0.6096385542168674, 'roc_auc': 0.7129241726015919}\n",
      "Model Training with the following Configurations: {'model_name': 'facebook/bart-base', 'strategy': 'concreteness_score_addition', 'num_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [02:07<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.6759259259259259, 'precision': 0.5565610859728507, 'recall': 0.5366568914956011, 'f1': 0.53125, 'roc_auc': 0.6653749476330122}\n",
      "Test Set Results: {'accuracy': 0.6944444444444444, 'precision': 0.5972797161442933, 'recall': 0.5689149560117301, 'f1': 0.5706024096385542, 'roc_auc': 0.699937159614579}\n",
      "Model Training with the following Configurations: {'model_name': 'facebook/bart-base', 'strategy': 'concreteness_score_addition', 'num_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [02:47<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.6851851851851852, 'precision': 0.5699728260869565, 'recall': 0.5431503979891077, 'f1': 0.5377061563640941, 'roc_auc': 0.669145370758274}\n",
      "Test Set Results: {'accuracy': 0.7222222222222222, 'precision': 0.6451803666469544, 'recall': 0.6028487641390867, 'f1': 0.6096385542168674, 'roc_auc': 0.708106409719313}\n",
      "Model Training with the following Configurations: {'model_name': 'facebook/bart-base', 'strategy': 'concreteness_score_addition', 'num_epochs': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 270/270 [03:28<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.6805555555555556, 'precision': 0.558413251961639, 'recall': 0.5350858818600754, 'f1': 0.5272623465600914, 'roc_auc': 0.6581483033095936}\n",
      "Test Set Results: {'accuracy': 0.7037037037037037, 'precision': 0.6089204912734325, 'recall': 0.5705906996229577, 'f1': 0.5714285714285715, 'roc_auc': 0.6981566820276497}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|██████████| 52.0/52.0 [00:00<00:00, 245kB/s]\n",
      "config.json: 100%|██████████| 474/474 [00:00<00:00, 2.54MB/s]\n",
      "vocab.json: 100%|██████████| 899k/899k [00:00<00:00, 3.95MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 4.69MB/s]\n",
      "pytorch_model.bin: 100%|██████████| 559M/559M [00:50<00:00, 11.1MB/s] \n",
      "Some weights of DebertaForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.weight', 'pooler.dense.bias', 'classifier.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 1728/1728 [00:00<00:00, 52007.44 examples/s]\n",
      "Map: 100%|██████████| 216/216 [00:00<00:00, 31259.74 examples/s]\n",
      "Map: 100%|██████████| 216/216 [00:00<00:00, 24498.25 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training with the following Configurations: {'model_name': 'microsoft/deberta-base', 'strategy': 'normal_finetuning', 'num_epochs': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/54 [00:00<?, ?it/s]You're using a DebertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "100%|██████████| 54/54 [01:02<00:00,  1.15s/it]\n",
      "/Users/saponaro/Developer/uni/noble-owl/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.7129629629629629, 'precision': 0.35648148148148145, 'recall': 0.5, 'f1': 0.41621621621621624, 'roc_auc': 0.4480519480519481}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saponaro/Developer/uni/noble-owl/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Results: {'accuracy': 0.7129629629629629, 'precision': 0.35648148148148145, 'recall': 0.5, 'f1': 0.41621621621621624, 'roc_auc': 0.5093213238374529}\n",
      "Model Training with the following Configurations: {'model_name': 'microsoft/deberta-base', 'strategy': 'normal_finetuning', 'num_epochs': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [02:15<00:00,  1.25s/it]\n",
      "/Users/saponaro/Developer/uni/noble-owl/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.7129629629629629, 'precision': 0.35648148148148145, 'recall': 0.5, 'f1': 0.41621621621621624, 'roc_auc': 0.6347926267281105}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saponaro/Developer/uni/noble-owl/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Results: {'accuracy': 0.7129629629629629, 'precision': 0.35648148148148145, 'recall': 0.5, 'f1': 0.41621621621621624, 'roc_auc': 0.6092375366568915}\n",
      "Model Training with the following Configurations: {'model_name': 'microsoft/deberta-base', 'strategy': 'normal_finetuning', 'num_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [03:24<00:00,  1.26s/it]\n",
      "/Users/saponaro/Developer/uni/noble-owl/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.7129629629629629, 'precision': 0.35648148148148145, 'recall': 0.5, 'f1': 0.41621621621621624, 'roc_auc': 0.7310431503979892}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saponaro/Developer/uni/noble-owl/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Results: {'accuracy': 0.7129629629629629, 'precision': 0.35648148148148145, 'recall': 0.5, 'f1': 0.41621621621621624, 'roc_auc': 0.6934436531210725}\n",
      "Model Training with the following Configurations: {'model_name': 'microsoft/deberta-base', 'strategy': 'normal_finetuning', 'num_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [04:43<00:00,  1.31s/it]\n",
      "/Users/saponaro/Developer/uni/noble-owl/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.7129629629629629, 'precision': 0.35648148148148145, 'recall': 0.5, 'f1': 0.41621621621621624, 'roc_auc': 0.7817343946376205}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saponaro/Developer/uni/noble-owl/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Results: {'accuracy': 0.7129629629629629, 'precision': 0.35648148148148145, 'recall': 0.5, 'f1': 0.41621621621621624, 'roc_auc': 0.7372224549643904}\n",
      "Model Training with the following Configurations: {'model_name': 'microsoft/deberta-base', 'strategy': 'normal_finetuning', 'num_epochs': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 270/270 [05:52<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.7129629629629629, 'precision': 0.64375, 'recall': 0.6348973607038123, 'f1': 0.6385620209435388, 'roc_auc': 0.756284038542103}\n",
      "Test Set Results: {'accuracy': 0.7314814814814815, 'precision': 0.6636904761904762, 'recall': 0.6382488479262672, 'f1': 0.6463015245623942, 'roc_auc': 0.7663908671973187}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 1728/1728 [00:00<00:00, 105140.53 examples/s]\n",
      "Map: 100%|██████████| 216/216 [00:00<00:00, 39472.36 examples/s]\n",
      "Map: 100%|██████████| 216/216 [00:00<00:00, 47420.55 examples/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Training with the following Configurations: {'model_name': 'microsoft/deberta-base', 'strategy': 'concreteness_score_addition', 'num_epochs': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:47<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.7037037037037037, 'precision': 0.6566332218506131, 'recall': 0.676581483033096, 'f1': 0.661839530332681, 'roc_auc': 0.7253875157100964}\n",
      "Test Set Results: {'accuracy': 0.6898148148148148, 'precision': 0.6349746144266692, 'recall': 0.6475701717637201, 'f1': 0.6390572390572391, 'roc_auc': 0.7218265605362378}\n",
      "Model Training with the following Configurations: {'model_name': 'microsoft/deberta-base', 'strategy': 'concreteness_score_addition', 'num_epochs': 2}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 108/108 [01:33<00:00,  1.16it/s]\n",
      "/Users/saponaro/Developer/uni/noble-owl/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.7129629629629629, 'precision': 0.35648148148148145, 'recall': 0.5, 'f1': 0.41621621621621624, 'roc_auc': 0.7680142438206954}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/saponaro/Developer/uni/noble-owl/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Results: {'accuracy': 0.7129629629629629, 'precision': 0.35648148148148145, 'recall': 0.5, 'f1': 0.41621621621621624, 'roc_auc': 0.7408881441139507}\n",
      "Model Training with the following Configurations: {'model_name': 'microsoft/deberta-base', 'strategy': 'concreteness_score_addition', 'num_epochs': 3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 162/162 [02:16<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.7129629629629629, 'precision': 0.6369047619047619, 'recall': 0.6156263091746963, 'f1': 0.6219085262563524, 'roc_auc': 0.7132383745286971}\n",
      "Test Set Results: {'accuracy': 0.7222222222222222, 'precision': 0.6491048593350384, 'recall': 0.6221198156682027, 'f1': 0.6296296296296295, 'roc_auc': 0.7328236279849184}\n",
      "Model Training with the following Configurations: {'model_name': 'microsoft/deberta-base', 'strategy': 'concreteness_score_addition', 'num_epochs': 4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 216/216 [03:10<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.7083333333333334, 'precision': 0.6292962356792144, 'recall': 0.607561793045664, 'f1': 0.6134859544976852, 'roc_auc': 0.7270632593213238}\n",
      "Test Set Results: {'accuracy': 0.7222222222222222, 'precision': 0.6502976190476191, 'recall': 0.6269375785504818, 'f1': 0.6341050254093732, 'roc_auc': 0.7204650188521157}\n",
      "Model Training with the following Configurations: {'model_name': 'microsoft/deberta-base', 'strategy': 'concreteness_score_addition', 'num_epochs': 5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 270/270 [03:57<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Set Results: {'accuracy': 0.7175925925925926, 'precision': 0.6443235977025541, 'recall': 0.6236908253037285, 'f1': 0.6302096489012377, 'roc_auc': 0.7269585253456221}\n",
      "Test Set Results: {'accuracy': 0.7314814814814815, 'precision': 0.6636904761904762, 'recall': 0.6382488479262672, 'f1': 0.6463015245623942, 'roc_auc': 0.6936531210724759}\n"
     ]
    }
   ],
   "source": [
    "result_list = list()\n",
    "for model_name in model_name_list:\n",
    "    \n",
    "    # Setting Model Name\n",
    "    kw_args[\"model_name\"] = model_name\n",
    "    \n",
    "    # Initializing ModellingExperiments Object\n",
    "    modelling_obj = ModellingExperiments(**kw_args)\n",
    "    \n",
    "    for strategy in strategies_list:\n",
    "        \n",
    "        # Preparing dataset for a specific strategy\n",
    "        modelling_obj.prepare_dataset(strategy=strategy)\n",
    "        \n",
    "        # Preparing data loaders\n",
    "        modelling_obj.prepare_dataloaders()\n",
    "            \n",
    "        # Training loop\n",
    "        for num_epochs in num_epochs_list:\n",
    "            # Initializing dictionary for storing results\n",
    "            result_dict = dict()\n",
    "            result_dict[\"model_name\"] = model_name\n",
    "            result_dict[\"strategy\"] = strategy\n",
    "            #result_dict[\"train_dataset_type\"] = train_dataset_type\n",
    "            result_dict[\"num_epochs\"] = num_epochs\n",
    "            print(\"Model Training with the following Configurations: {}\".format(result_dict))\n",
    "            \n",
    "            # For a specic num_epochs variable, we are setting up the optimizers\n",
    "            modelling_obj.setup_optimizer(num_epochs=num_epochs)\n",
    "            \n",
    "            # Now, we are training the model\n",
    "            modelling_obj.train_model()\n",
    "            \n",
    "            # Now, we will evaluate the model on validation dataset\n",
    "            modelling_obj.eval_model(modelling_obj.validation_dataloader)\n",
    "            \n",
    "            # Storing results on validation set\n",
    "            for k, v in modelling_obj.eval_dict.items():\n",
    "                result_dict[\"validation_{}\".format(k)] = v\n",
    "            print(\"Validation Set Results: {}\".format(modelling_obj.eval_dict))\n",
    "            \n",
    "            # Now, we will evaluate the model on test dataset\n",
    "            modelling_obj.eval_model(modelling_obj.test_dataloader)\n",
    "            \n",
    "            # Storing results on test set\n",
    "            for k, v in modelling_obj.eval_dict.items():\n",
    "                result_dict[\"test_{}\".format(k)] = v\n",
    "            \n",
    "            print(\"Test Set Results: {}\".format(modelling_obj.eval_dict))\n",
    "            \n",
    "            # Storing all the results in the results_list\n",
    "            result_list.append(result_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>strategy</th>\n",
       "      <th>num_epochs</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>validation_precision</th>\n",
       "      <th>validation_recall</th>\n",
       "      <th>validation_f1</th>\n",
       "      <th>validation_roc_auc</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>facebook/bart-base</td>\n",
       "      <td>normal_finetuning</td>\n",
       "      <td>1</td>\n",
       "      <td>0.712963</td>\n",
       "      <td>0.356481</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.416216</td>\n",
       "      <td>0.552891</td>\n",
       "      <td>0.712963</td>\n",
       "      <td>0.356481</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.416216</td>\n",
       "      <td>0.543884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>facebook/bart-base</td>\n",
       "      <td>normal_finetuning</td>\n",
       "      <td>2</td>\n",
       "      <td>0.754630</td>\n",
       "      <td>0.716931</td>\n",
       "      <td>0.615941</td>\n",
       "      <td>0.624988</td>\n",
       "      <td>0.792417</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.555466</td>\n",
       "      <td>0.528697</td>\n",
       "      <td>0.514799</td>\n",
       "      <td>0.725073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>facebook/bart-base</td>\n",
       "      <td>normal_finetuning</td>\n",
       "      <td>3</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>0.683891</td>\n",
       "      <td>0.601382</td>\n",
       "      <td>0.607018</td>\n",
       "      <td>0.768538</td>\n",
       "      <td>0.731481</td>\n",
       "      <td>0.662366</td>\n",
       "      <td>0.594889</td>\n",
       "      <td>0.599488</td>\n",
       "      <td>0.740050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>facebook/bart-base</td>\n",
       "      <td>normal_finetuning</td>\n",
       "      <td>4</td>\n",
       "      <td>0.671296</td>\n",
       "      <td>0.555111</td>\n",
       "      <td>0.538228</td>\n",
       "      <td>0.534808</td>\n",
       "      <td>0.702870</td>\n",
       "      <td>0.754630</td>\n",
       "      <td>0.701872</td>\n",
       "      <td>0.640029</td>\n",
       "      <td>0.652744</td>\n",
       "      <td>0.742250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>facebook/bart-base</td>\n",
       "      <td>normal_finetuning</td>\n",
       "      <td>5</td>\n",
       "      <td>0.680556</td>\n",
       "      <td>0.553292</td>\n",
       "      <td>0.530268</td>\n",
       "      <td>0.519706</td>\n",
       "      <td>0.681609</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.622121</td>\n",
       "      <td>0.588291</td>\n",
       "      <td>0.592953</td>\n",
       "      <td>0.713553</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           model_name           strategy  num_epochs  validation_accuracy  \\\n",
       "0  facebook/bart-base  normal_finetuning           1             0.712963   \n",
       "1  facebook/bart-base  normal_finetuning           2             0.754630   \n",
       "2  facebook/bart-base  normal_finetuning           3             0.740741   \n",
       "3  facebook/bart-base  normal_finetuning           4             0.671296   \n",
       "4  facebook/bart-base  normal_finetuning           5             0.680556   \n",
       "\n",
       "   validation_precision  validation_recall  validation_f1  validation_roc_auc  \\\n",
       "0              0.356481           0.500000       0.416216            0.552891   \n",
       "1              0.716931           0.615941       0.624988            0.792417   \n",
       "2              0.683891           0.601382       0.607018            0.768538   \n",
       "3              0.555111           0.538228       0.534808            0.702870   \n",
       "4              0.553292           0.530268       0.519706            0.681609   \n",
       "\n",
       "   test_accuracy  test_precision  test_recall   test_f1  test_roc_auc  \n",
       "0       0.712963        0.356481     0.500000  0.416216      0.543884  \n",
       "1       0.685185        0.555466     0.528697  0.514799      0.725073  \n",
       "2       0.731481        0.662366     0.594889  0.599488      0.740050  \n",
       "3       0.754630        0.701872     0.640029  0.652744      0.742250  \n",
       "4       0.708333        0.622121     0.588291  0.592953      0.713553  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(result_list)\n",
    "results_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv('../../results/FinalResultsPAP.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
